{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extensive-program",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-hypothesis",
   "metadata": {
    "executionInfo": {
     "elapsed": 3536,
     "status": "ok",
     "timestamp": 1634420095364,
     "user": {
      "displayName": "Kaitlin Pet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17883318583265264622"
     },
     "user_tz": 240
    },
    "id": "failing-hypothesis"
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.fftpack\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy import stats\n",
    "import math\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.io.wavfile import write\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import iqr\n",
    "import music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-raise",
   "metadata": {
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1634420128534,
     "user": {
      "displayName": "Kaitlin Pet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17883318583265264622"
     },
     "user_tz": 240
    },
    "id": "complex-raise"
   },
   "outputs": [],
   "source": [
    "# Constants for reading .times or .ideal files\n",
    "\n",
    "SECONDS_PER_AT_FRAME = 256/8000\n",
    "\n",
    "fft_size=1024\n",
    "\n",
    "\n",
    "hop_size=int(fft_size/4)\n",
    "sr_ensemble=44100\n",
    "\n",
    "\n",
    "fft_lim =513 #largest bin size for cutoff\n",
    "\n",
    "#X seconds/sample * 512 samples/STFT frame\n",
    "\n",
    "def seconds_to_stft_frames(seconds):\n",
    "    samples = seconds * sr_ensemble\n",
    "    return  math.floor((samples)/hop_size)\n",
    "\n",
    "\n",
    "def stft_frames_to_seconds(stft_frames):\n",
    "    samples = fft_size + (stft_frames-1)*hop_size\n",
    "    return samples/sr_ensemble\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "half_step = 1/12 #multiply this by change to get "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-digit",
   "metadata": {
    "id": "further-digit"
   },
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-casino",
   "metadata": {
    "id": "engaged-casino"
   },
   "source": [
    "### Load files describing original timepoints and unaltered audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-hello",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1634420132171,
     "user": {
      "displayName": "Kaitlin Pet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17883318583265264622"
     },
     "user_tz": 240
    },
    "id": "dangerous-hello",
    "outputId": "d5ef3e2f-0e21-43b0-b6c2-b455d6edf0a5"
   },
   "outputs": [],
   "source": [
    "path_to_ensemble_times=\"../../orchestra_part_times/mozart_serenade_eflat.\" #partial path for parsing\n",
    "\n",
    "path_to_ensemble_audio=\"../../orchestra_part_audio/mozart_serenade_eflat.\" #partial path for parsing\n",
    "\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "other_instrument_dct = {\n",
    "                 \"oboe_1\":[ \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"],\n",
    "                 \"oboe_2\":\n",
    "                  [\"oboe_1\",   \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"],\n",
    "    \n",
    "                  \"clarinet_1\": \n",
    "                [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                    \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"], \n",
    "    \n",
    "                  \"clarinet_2\":\n",
    "                 [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"],\n",
    "    \n",
    "                  \"bassoon_1\":\n",
    "                 [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"],\n",
    "    \n",
    "    \n",
    "                  \"bassoon_2\":\n",
    "                 [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"],\n",
    "    \n",
    "                  \"horn_in_e_1\": \n",
    "                 [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_2\"], \n",
    "                  \"horn_in_e_2\":\n",
    "                 [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\"]\n",
    "}\n",
    "#number of parts\n",
    "num_voices=8\n",
    "#sanity check\n",
    "num_voices == len(instrument_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-pacific",
   "metadata": {
    "id": "dense-pacific"
   },
   "source": [
    "Load Original Parts Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-professor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28219,
     "status": "ok",
     "timestamp": 1634420160637,
     "user": {
      "displayName": "Kaitlin Pet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17883318583265264622"
     },
     "user_tz": 240
    },
    "id": "burning-professor",
    "outputId": "2a05e3f2-ebea-41cb-8ecf-c4ae683f1622"
   },
   "outputs": [],
   "source": [
    "#Load each file into a list\n",
    "ensemble_audio_lst = []\n",
    "sr_dct={}\n",
    "for instr in instrument_lst:\n",
    "    print(instr)\n",
    "    samples, sr = librosa.load(path_to_ensemble_audio+instr+\".wav\", sr=None)\n",
    "    if sr==sr_ensemble:\n",
    "        samples_48k=samples\n",
    "    else:\n",
    "        samples_48k = librosa.resample(samples, sr, sr_ensemble, 'kaiser_fast')\n",
    "    ensemble_audio_lst.append(samples_48k)\n",
    "\n",
    "\n",
    "#should be (num_instruments, length_samples)\n",
    "ensemble_audio_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-provision",
   "metadata": {
    "executionInfo": {
     "elapsed": 5664,
     "status": "ok",
     "timestamp": 1634420166282,
     "user": {
      "displayName": "Kaitlin Pet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17883318583265264622"
     },
     "user_tz": 240
    },
    "id": "rapid-provision"
   },
   "outputs": [],
   "source": [
    "#\n",
    "part_stfts = [ ]\n",
    "\n",
    "for i in  range(0, num_voices):\n",
    "    part_stfts.append(\n",
    "        librosa.stft(ensemble_audio_lst[i], n_fft=fft_size, hop_length=hop_size, center=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-diameter",
   "metadata": {},
   "source": [
    "## Create list of STFTs for each part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-empire",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1634420166283,
     "user": {
      "displayName": "Kaitlin Pet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17883318583265264622"
     },
     "user_tz": 240
    },
    "id": "demographic-empire",
    "outputId": "ea02e61f-097a-4e7a-fb3f-30cf3caf8e27"
   },
   "outputs": [],
   "source": [
    "part_stfts[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-wilson",
   "metadata": {
    "id": "optimum-wilson"
   },
   "source": [
    "### Extract data from each times file and tunign file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-rescue",
   "metadata": {
    "id": "matched-rescue"
   },
   "outputs": [],
   "source": [
    "path_to_ensemble_tun = '../../tuning/mozart_serenade_eflat.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-maintenance",
   "metadata": {
    "id": "wrong-maintenance"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_dct={} #list with dataframe corresponding to each one \n",
    "\n",
    "\n",
    "\n",
    "for instr in instrument_lst:\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Read in .times file as dataframe\n",
    "    '''\n",
    "    times_df = pd.read_csv(path_to_ensemble_times+instr+\".times\", \n",
    "                              header=None,\n",
    "                              delim_whitespace=True,\n",
    "                              names=['measure', 'AT', 'marked'])\n",
    "\n",
    "\n",
    "    '''\n",
    "    Read in tuning file\n",
    "    '''\n",
    "    tun_df = pd.read_csv(path_to_ensemble_tun+instr+\".tun\", \n",
    "                              header=None,\n",
    "                              delim_whitespace=True,\n",
    "                              names=['measure','shift (half step)'])\n",
    "\n",
    "    #parse out the word 'solo' so can join with times df\n",
    "    remove_solo = lambda x: x[5:len(x)]\n",
    "\n",
    "    tun_df['measure']=list(map(remove_solo, tun_df['measure']))\n",
    "    \n",
    "    '''\n",
    "    get absolute pitch shift by multiplying by half step constant \n",
    "    '''\n",
    "    get_abs_tun = lambda x: 2 ** (-1*x*half_step)#Guessing positive value -> flatter\n",
    "    \n",
    "    tun_df['tune (abs)'] = list(map(get_abs_tun, tun_df['shift (half step)']))\n",
    "\n",
    "    '''\n",
    "    Don't care about marked\n",
    "    '''\n",
    "    times_df = times_df[['measure', 'AT']]\n",
    "\n",
    "    '''\n",
    "    Remove extra rows\n",
    "    '''\n",
    "\n",
    "    times_df=times_df[4:len(times_df)-1].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Join\n",
    "    '''\n",
    "    times_df= times_df.set_index('measure').join(tun_df.set_index('measure')).reset_index()\n",
    "    \n",
    "    '''\n",
    "    use mapping to cast measure\n",
    "    '''\n",
    "    evalfun = lambda x: eval(x)\n",
    "    evaluatedMeasure=list(map(evalfun, times_df['measure']))\n",
    "\n",
    "    times_df['eval_measure']=evaluatedMeasure        \n",
    "\n",
    "\n",
    "    '''\n",
    "    use mapping to AT to float\n",
    "    '''\n",
    "    try:\n",
    "        evaluatedsec=list(map(evalfun, times_df['AT']))\n",
    "        times_df['AT']=evaluatedsec\n",
    "    except:\n",
    "        print(\"casting done automatically by pandas\")\n",
    "\n",
    "        \n",
    "    '''\n",
    "    Pad last element AT (so it doesn't cut off)\n",
    "    '''\n",
    "    times_df['AT'].iloc[-1]= times_df.iloc[-1]['AT']+15\n",
    "\n",
    "    '''\n",
    "    Convert AT to seconds\n",
    "    '''\n",
    "    times_df['Seconds']=times_df['AT']*SECONDS_PER_AT_FRAME \n",
    "\n",
    "    '''\n",
    "    Get STFT frame number at each timepoint\n",
    "    '''\n",
    "\n",
    "    evaluatedstft=list(map(seconds_to_stft_frames, times_df['Seconds']))\n",
    "      \n",
    "\n",
    "    times_df['STFT frames']=evaluatedstft\n",
    "\n",
    "    '''\n",
    "    Add to dictionary\n",
    "    '''\n",
    "    df_dct[instr]=times_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-illustration",
   "metadata": {},
   "source": [
    "# Remove Ghost Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mid =\"../../mozart_serenade_eflat/mozart_serenade_eflat.mid\"\n",
    "\n",
    "\n",
    "mid_instrument_lst= ['oboe_1',\n",
    " 'oboe_2',\n",
    " 'clarinet_1',\n",
    " 'clarinet_2',\n",
    "                      'horn_in_e_1',\n",
    " 'horn_in_e_2',\n",
    " 'bassoon_1',\n",
    " 'bassoon_2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "For a given part gets music21 notes/chords, measure metric used in Cadenza, \n",
    "    and each note's offset in quarter notes\n",
    "Params:\n",
    "part: music21.stream.Part, part to parse\n",
    "\n",
    "Returns: \n",
    "\n",
    "list of music21 notes/chords, measure metric used in Cadenza, \n",
    "    and each note's offset in quarter notes\n",
    "\n",
    "Returns :\n",
    "offsets, eval_measures, notes- lists of.....\n",
    "    'notes': music21 note/chords\n",
    "    'evaluated_measure' : used in Cadenza\n",
    "    'beat position' : note offset in quarter note beats \n",
    "'''\n",
    "def extract_info_from_part(part):\n",
    "    offsets=[] #offset in beats\n",
    "    eval_measures=[] #same form as cadenza\n",
    "    notes=[] #music21 note or chord\n",
    "    cur_measure_offset=0\n",
    "\n",
    "    for measure in part.getElementsByClass(music21.stream.Measure):\n",
    "        \n",
    "        if measure.timeSignature != None:\n",
    "            cur_ts = measure.timeSignature\n",
    "            beatVal = 2 **(2-math.log(cur_ts.denominator)/math.log(2))\n",
    "            num_beats = cur_ts.numerator\n",
    "            measure_len = beatVal * num_beats\n",
    "\n",
    "        \n",
    "        \n",
    "        for note in list(measure.recurse().notes):\n",
    "            offsets.append(cur_measure_offset + note.offset)\n",
    "            eval_measures.append(measure.number + note.offset/4)\n",
    "            notes.append(note)\n",
    "        cur_measure_offset += measure_len\n",
    "    \n",
    "    return offsets, eval_measures, notes\n",
    "\n",
    "b = music21.converter.parse(path_to_mid)\n",
    "b.show('text')\n",
    "\n",
    "\n",
    "parts = b.getElementsByClass(music21.stream.Part)\n",
    "for i in range(8):\n",
    "    print('ON INDEX', i)\n",
    "    parts[i][0].show('text')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(parts)):\n",
    "    part_info= extract_info_from_part(parts[i])\n",
    "    keep_times = [float(time) for time in part_info[1]]\n",
    "    instr_df = df_dct[mid_instrument_lst[i]]\n",
    "    #append last time \n",
    "    keep_times.append(instr_df['eval_measure'].iloc[-1])\n",
    "    locations = instr_df[instr_df['eval_measure'].isin(keep_times)].index\n",
    "    new_df = instr_df.loc[locations].reset_index(drop=True)\n",
    "    print(part_info[2])\n",
    "    print(new_df)\n",
    "    df_dct[mid_instrument_lst[i]]=new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-birthday",
   "metadata": {},
   "source": [
    "## Audio Stretching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift_stretch1(audio_samples_full, start_sample, \n",
    "                         end_sample, prev_phase, sr, \n",
    "                         shift_constant, \n",
    "                         desired_frame_num, \n",
    "                         first_note, fft_size, hop_size, window, fft_height):\n",
    "\n",
    "    \n",
    "    '''\n",
    "    We want audio from start of current frame to fft_size past ending point to calculate phases.\n",
    "    Will only use last frame to calculate phase advance - will not save modulus\n",
    "    \n",
    "      note start \n",
    "       |----\n",
    "         ----\n",
    "          ---- \n",
    "           ---- note end\n",
    "            ----|\n",
    "             ---|-\n",
    "              --|--\n",
    "               -|---\n",
    "                |----\n",
    "    '''\n",
    "    \n",
    "    audio_samples = audio_samples_full[start_sample:end_sample+fft_size*2] \n",
    "    #** fft_size *2 gives some buffer audio for ptich shifting (want at least fft_size)\n",
    "    #print(\"shape of audio_samples is \",audio_samples.shape)\n",
    "    \n",
    "    '''\n",
    "    Part I: Perform Pitch shift on all audio \n",
    "    '''\n",
    "    #print(\"fft_size \", fft_size)\n",
    "    #print(\"hop size\", hop_size)\n",
    "    N_note=len(audio_samples)\n",
    "    total_time = N_note/sr_ensemble\n",
    "    \n",
    "    #original timepoints\n",
    "    x = np.linspace(0, total_time, num=N_note, endpoint=True)\n",
    "\n",
    "    #interpolation function \n",
    "    sample_interpolation = interp1d(x, audio_samples, kind='linear')\n",
    "\n",
    "    #New timepoints\n",
    "    xshift = np.linspace(0, total_time, num=int(N_note/shift_constant), endpoint=True) \n",
    "    #apply interpolation function to new timepoints\n",
    "    yshift = sample_interpolation(xshift)\n",
    "\n",
    "    '''\n",
    "    Part II: Time stretch\n",
    "    \n",
    "    We want new audio to occupy desired_frame_num amount of frames \n",
    "    Generate  desired_frames+1 timepoints from [start_sample to end_sample]\n",
    "    For each timepoint except first, phase differential is difference between phase of current timepoint fft \n",
    "                and phase of current timepoint - (hop size?) fft \n",
    "                ** test what happens when this is previous index fft differential \n",
    "    \n",
    "    \n",
    "    If we are at beginning, initial phase is preserved as first phase difference\n",
    "    Else, we are plugging in the last calculated phase difference of previous note\n",
    "    '''\n",
    "    \n",
    "    #timpoints  \n",
    "    N_shifted = int((end_sample-start_sample)/shift_constant) #want start of first note to start of next_note \n",
    "    timepoints = np.linspace(0, N_shifted, num=desired_frame_num+1, endpoint=True).round(0).astype(int)\n",
    "\n",
    "    #iterate through creating frames - making 1 extra \n",
    "    mod = np.zeros((int(fft_size/2)+1, desired_frame_num+1))\n",
    "    diff_phase = np.zeros(mod.shape)\n",
    "\n",
    "    for i in range(desired_frame_num+1): \n",
    "\n",
    "        #Get position from timepoints \n",
    "        sample_index = timepoints[i]\n",
    "        \n",
    "        #Create fft starting from sample index \n",
    "        chunk1start=sample_index\n",
    "        chunk1end=chunk1start+fft_size\n",
    "        chunk1 = yshift[chunk1start:chunk1end] *window\n",
    "        fft1= fft(chunk1)\n",
    "        \n",
    "        #Mod\n",
    "        mod[:,i]=np.abs(fft1[0:fft_height ])\n",
    "\n",
    "        #Phase \n",
    "        \n",
    "        if i==0:\n",
    "            \n",
    "            #if it's the first note, keep its current phase \n",
    "            if first_note == True:\n",
    "                frame_phase = np.angle(fft1)\n",
    "                diff_phase[:,0] = frame_phase[0:fft_height ]\n",
    "            #otherwise sub in last phase advance \n",
    "            else:\n",
    "                diff_phase[:,0:1] = prev_phase\n",
    "        else:\n",
    "            #phase differential is calculated based on fft starting at cur_position - hop_size \n",
    "            chunk2start = sample_index-hop_size\n",
    "                \n",
    "            chunk2end = chunk2start+fft_size\n",
    "            #If we're going sharp, first value will be less than 0\n",
    "            if chunk2start <0:\n",
    "                chunk2=np.zeros(fft_size)\n",
    "                chunk2[0-chunk2start:]=yshift[0:chunk2end]\n",
    "                chunk2=chunk2*window\n",
    "            #normal case \n",
    "            else:\n",
    "                chunk2 = yshift[chunk2start : chunk2end]*window\n",
    "            fft2 = fft(chunk2) \n",
    "            \n",
    "            #take difference \n",
    "            frame_phase = np.angle(fft1)[0:fft_height ]-np.angle(fft2)[0:fft_height ] \n",
    "            diff_phase[:,i]=frame_phase\n",
    "\n",
    "    #Remove last element, saving the phase advance\n",
    "    \n",
    "    joining_phase_advance = diff_phase[:, -1:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    diff_phase = diff_phase [:, 0:-1]\n",
    "    mod=mod[:, 0:-1]\n",
    "    \n",
    "    return mod, diff_phase, joining_phase_advance\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocode_to_new_frames(df, part_samples, new_end_time):\n",
    "    #new end time and new end frame should be same for everyone (if not some can be cut )\n",
    "\n",
    "     #constants\n",
    "    new_end_frame = seconds_to_stft_frames(new_end_time)\n",
    "    window=scipy.signal.windows.hann(fft_size)\n",
    "    fft_height = int(fft_size/2+1) #height of fft (# bins)\n",
    "\n",
    "\n",
    "    #fillable arrays\n",
    "    vocoded_mod= np.zeros((fft_height, new_end_frame))\n",
    "    vocoded_diff_phase= np.zeros((fft_height, new_end_frame))\n",
    "\n",
    "    start_og_sample = int(df.iloc[0]['Seconds']*sr_ensemble)#Audio frame in original playing begins\n",
    "    start_new_frame = df.iloc[0]['New STFT frames']\n",
    "\n",
    "    num_measures = len(df)\n",
    "    for i in range(0, num_measures-1):\n",
    "\n",
    "        end_og_sample = int(df.iloc[i+1]['Seconds']*sr_ensemble)\n",
    "        end_new_frame = df.iloc[i+1]['New STFT frames']\n",
    "\n",
    "        #print(start_og_sample, \"start og sample\")\n",
    "        #print(end_og_sample, \"end og sample\")\n",
    "\n",
    "\n",
    "        pitch_shift = df.iloc[i]['tune (abs)']\n",
    "        #print(\"************\\n\"+df.iloc[i]['measure'])\n",
    "        #print(\"shifting to pitch \", pitch_shift)\n",
    "        #Calculate nessesary time stretch\n",
    "        if end_og_sample < start_og_sample:\n",
    "            print(\"END OG FRAME IS LESS THAN START OG FRAME\")\n",
    "            print(start_og_sample)\n",
    "            print(end_og_sample)\n",
    "\n",
    "        new_frame_dif = end_new_frame - start_new_frame\n",
    "\n",
    "\n",
    "        '''\n",
    "        Changes\n",
    "\n",
    "        Hypothesis from test 2: just STFT process resutls in 1 more? frame than expected\n",
    "        Resutl: \n",
    "        '''        \n",
    "\n",
    "\n",
    "        #if we are on first chord, preserve initial phase \n",
    "        if i==0:\n",
    "\n",
    "\n",
    "            mod, diff_phase, end_phase = pitch_shift_stretch1(audio_samples_full=part_samples,\n",
    "                                                              start_sample=start_og_sample, end_sample=end_og_sample, \n",
    "                                                              prev_phase=None, sr=sr_ensemble, shift_constant=pitch_shift, \n",
    "                                                              desired_frame_num = new_frame_dif, first_note=True, \n",
    "                                                              fft_size=fft_size, hop_size=hop_size, \n",
    "                                                              window=window, fft_height=fft_height)\n",
    "\n",
    "        else:\n",
    "\n",
    "\n",
    "            mod, diff_phase, end_phase = pitch_shift_stretch1(audio_samples_full=part_samples,\n",
    "                                                              start_sample=start_og_sample, end_sample=end_og_sample, \n",
    "                                                              prev_phase=end_phase, sr=sr_ensemble, shift_constant=pitch_shift, \n",
    "                                                              desired_frame_num = new_frame_dif, first_note=False, \n",
    "                                                              fft_size=fft_size, hop_size=hop_size, \n",
    "                                                              window=window, fft_height=fft_height)\n",
    "\n",
    "\n",
    "        correct_len = end_new_frame-start_new_frame\n",
    "        #print(\"length should be \", correct_len)\n",
    "        #print(\"new chunk shape\", mod.shape[1])\n",
    "\n",
    "\n",
    "        #Put vocoded chunk in final STFT\n",
    "\n",
    "        vocoded_mod[:,start_new_frame:end_new_frame]=mod\n",
    "        vocoded_diff_phase[:,start_new_frame:end_new_frame]=diff_phase\n",
    "        \n",
    "        #increment samples\n",
    "\n",
    "        start_og_sample = end_og_sample\n",
    "        start_new_frame = end_new_frame\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return vocoded_mod, vocoded_diff_phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_final_parts(ensemble_audio_lst,df_dct,instrument_lst, end_pad ): #end pad is in ms\n",
    "    adj_part_lst = []\n",
    "    \n",
    "    #pick longest for new_end_time\n",
    "    new_end_time = 0\n",
    "    for voice in instrument_lst:\n",
    "        \n",
    "        cand_end_time = df_dct[voice].iloc[len(df_dct[voice])-1]['new_times']+end_pad\n",
    "        \n",
    "        if cand_end_time> new_end_time:\n",
    "            new_end_time = cand_end_time\n",
    "    for i in range(0, len(instrument_lst)):\n",
    "        print(\"***************************************************************************************************\")\n",
    "        print(\"Instrument: \",instrument_lst[i] )\n",
    "        #get correct stft and dataframe to describe instrument\n",
    "        part_samples=ensemble_audio_lst[i]\n",
    "        df = df_dct[instrument_lst[i]]\n",
    "        #vocode part so it fits the new timing scheme\n",
    "        vocoded_mod, vocoded_diff_phase = vocode_to_new_frames(df, part_samples, new_end_time)\n",
    "        cum_resampled_phase = np.cumsum(vocoded_diff_phase, axis=1)\n",
    "\n",
    "        #combine modulus and argument to make final stft\n",
    "        cum_stft = vocoded_mod*np.exp(1j*cum_resampled_phase) \n",
    "\n",
    "        #add to list\n",
    "        adj_part_lst.append(cum_stft)\n",
    "    return adj_part_lst    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_parts(adj_part_lst):\n",
    "        #sum parts \n",
    "    sum_vocoded_stft= np.zeros((int(fft_size/2+1), adj_part_lst[0].shape[1]), dtype='complex')\n",
    "    for i in range(0, len(instrument_lst)):\n",
    "        #add waves\n",
    "        sum_vocoded_stft += adj_part_lst[i]*nonvar_mix[i]\n",
    "        \n",
    "    #convert to audio sphere\n",
    "    adjusted_by_measure = librosa.istft(sum_vocoded_stft,  hop_length=hop_size)\n",
    "    return adjusted_by_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mix_parts(adj_part_lst, nonvar_mix, folder_path = None):\n",
    "    \n",
    "    if folder_path==None:\n",
    "        print(\"Must supply path of folder to write parts. Create first\")\n",
    "        return 0\n",
    "    print(\"writing to \"+folder_path)    \n",
    "    #list of parts   \n",
    "    part_samples_lst = []\n",
    "    \n",
    "    for i in range(0, len(instrument_lst)):\n",
    "        #convert into sample space\n",
    "        samples_float = librosa.istft(adj_part_lst[i]*nonvar_mix[i],hop_length=hop_size)\n",
    "        samples_int = (2**16*samples_float).astype(np.int16)\n",
    "        part_samples_lst.append(samples_int)\n",
    "        print(\"writing part for \", instrument_lst[i])\n",
    "        write(folder_path+\"/\"+instrument_lst[i]+\".wav\", sr_ensemble, samples_int)\n",
    "        \n",
    "\n",
    "    return part_samples_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input df version with NaN, so we can fill with w_i\n",
    "#w_i must be less than 1/n_p\n",
    "def make_weight_arr(comb_df,instrument_lst, w_i ):\n",
    "    \n",
    "    weight_arr = comb_df[instrument_lst].fillna(w_i).to_numpy()\n",
    "    weight_arr[weight_arr>w_i ] = 0 #value to be filled\n",
    "    sums = 1- np.sum(weight_arr, axis=1)\n",
    "    for i in range(len(weight_arr)):\n",
    "        row = weight_arr[i]\n",
    "        num_actual_voices = num_voices-np.count_nonzero(row)\n",
    "        weight = sums[i]/num_actual_voices\n",
    "        #print(weight)\n",
    "        row[row ==0]=weight\n",
    "        weight_arr[i]=row\n",
    "        print(weight_arr[i])\n",
    "    return weight_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-dominican",
   "metadata": {},
   "source": [
    "## Constants for nonvariable mix\n",
    "- for final version do manual adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonvar_mix = np.array([[0.1222869 ],\n",
    "       [0.26452896* .75],\n",
    "       [0.20447949*2],\n",
    "       [0.63013774],\n",
    "       [0.2666939*.75 ],\n",
    "       [1.8622239 ],\n",
    "       [0.322688  ],\n",
    "       [0.3939167* 1.2 ]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-membership",
   "metadata": {},
   "source": [
    "# Create df with all eval_measure and STFT frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_STFT_dct={}\n",
    "\n",
    "for v in instrument_lst:\n",
    "    df_STFT_dct[v]= df_dct[v][['eval_measure', 'STFT frames']]\n",
    "    df_STFT_dct[v][v]=df_STFT_dct[v]['STFT frames']\n",
    "    df_STFT_dct[v]=df_STFT_dct[v][['eval_measure', v]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = df_STFT_dct['oboe_1'].set_index('eval_measure')\n",
    "\n",
    "for v in instrument_lst[1:]:\n",
    "    comb_df = comb_df.join(\n",
    "    df_STFT_dct[v].set_index('eval_measure'), \n",
    "    #on = 'eval_measure', \n",
    "    how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = comb_df.reset_index()\n",
    "comb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-wagon",
   "metadata": {},
   "source": [
    "### Extrapolate missing values for mean calculation\n",
    "\n",
    "- Want tempo in interpolated sections to accelerate from tempo_old to tempo_new. \n",
    "- Method 1: Avg tempo\n",
    "    - Extrapolate forward from prev section and backward from next section. Average times. \n",
    "- Method 2: Weighted avg tempo\n",
    "    - Closer to forward implies tempo closer to forward, closer to backward implies tempo closer to backward. Constants calculated based from measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part measures is df_dct[v]['eval_measure']\n",
    "#max_dist is maximum gap between adjacent notes (in measures)\n",
    "'''\n",
    "Aim: everything under 2 measures is interpolated linearly, otherwise tempo extrapolated \n",
    "'''\n",
    "def find_blocks(part_measures, max_dist = 1):\n",
    "    block_lst = []\n",
    "    cur_block = []\n",
    "    for i in range(len(part_measures)-1):\n",
    "\n",
    "        cur_measure = part_measures[i]\n",
    "        cur_block.append(i)\n",
    "        #check distance from next block\n",
    "        next_measure = part_measures[i+1]\n",
    "\n",
    "        if next_measure - cur_measure > max_dist : \n",
    "            #single notes do not constitute block\n",
    "            if len(cur_block)>1:\n",
    "                block_lst.append(cur_block)\n",
    "            cur_block = []\n",
    "    if len(cur_block)>0:\n",
    "        cur_block.append(len(part_measures)-1) #add last element\n",
    "        block_lst.append(cur_block)\n",
    "    return block_lst   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_extrapolate_df(nan_df, df_dct, all_measures, method = \"avg\"):\n",
    "    extrap_df = nan_df.copy()\n",
    "\n",
    "    for v in instrument_lst:\n",
    "        x = np.array(df_dct[v]['eval_measure'])\n",
    "        print(x)\n",
    "        y = np.array(df_dct[v]['STFT frames']) \n",
    "        blocks = find_blocks(x)\n",
    "        \n",
    "        print(\"BLOCKS\\n\", blocks)\n",
    "        #store extrapolations\n",
    "        forward_extrapolation_lst = []\n",
    "        backward_extrapolation_lst =[]\n",
    "        for i in range(len(blocks)):\n",
    "            print(\"\\n******************************\\nOn block\", i, \"\\n*******\")\n",
    "            block = blocks[i]\n",
    "            '''\n",
    "            1. Interpolate within blocks to get locations of local rests\n",
    "            '''\n",
    "            #fit function\n",
    "            \n",
    "            print(\"fitting: \", x[block], \"to\", y[block])\n",
    "            f = interp1d(x[block], y[block] , fill_value = 'extrapolate')\n",
    "            #figure out combined index locations \n",
    "            start_measure = x[block[0]]\n",
    "            end_measure = x[block[-1]]\n",
    "            print(\"starting on measure\", start_measure, \"ending on measure\", end_measure)\n",
    "            start_comb_idx = all_measures.index(start_measure)\n",
    "            end_comb_idx = all_measures.index(end_measure)\n",
    "            print('In full version starts on index', start_comb_idx, \"and ends on index\",  end_comb_idx)\n",
    "            #perform interpolation within block \n",
    "            y1 = f(all_measures[start_comb_idx: end_comb_idx+1]) #including ending index for interpolation\n",
    "            print(\"After interpolation:\", all_measures[start_comb_idx: end_comb_idx+1],\n",
    "                 \"maps to \", y1)\n",
    "\n",
    "            #assign\n",
    "            extrap_df[v].loc[start_comb_idx: end_comb_idx] = y1\n",
    "            print(\"currently, dataframe is \\n\", extrap_df[v])\n",
    "            \n",
    "            '''\n",
    "            2. Perform forward extrapolation \n",
    "            '''\n",
    "            print(\"\\n&&&&\\nExtrapolation\")\n",
    "            #start extrapolation at last value of current block\n",
    "            forward_extrap_start = x[blocks[i][-1]]\n",
    "            #end extrapolation on first value of next block or end of piece\n",
    "            if i < len(blocks)-1:\n",
    "                forward_extrap_end = x[blocks[i+1][0]]\n",
    "            else:\n",
    "                forward_extrap_end = all_measures[-1]\n",
    "            #extrapolate vals\n",
    "            \n",
    "            forward_start_idx = all_measures.index(forward_extrap_start)\n",
    "            forward_end_idx = all_measures.index(forward_extrap_end)\n",
    "            #measures slice\n",
    "            forward_x = all_measures[forward_start_idx: forward_end_idx+1 ] #include end\n",
    "            forward_y = f(forward_x)\n",
    "            print(\"In forward extrapolation: mapped\", forward_x, \"to\", forward_y)\n",
    "            #make start 0 to get differences \n",
    "            forward_y = forward_y - forward_y[0]\n",
    "            \n",
    "            #add x y pairs to dictionary\n",
    "            forward_extrapolation_lst.append({'startval':forward_start_idx, \n",
    "                                              'endval':forward_end_idx,\n",
    "                                              'y':forward_y})\n",
    "            '''\n",
    "            2. Perform backward extrapolation \n",
    "            '''\n",
    "            #start at beginning of piece or end of last block\n",
    "            if i > 0:\n",
    "                backward_extrap_start = x[blocks[i-1][-1]]\n",
    "            else:\n",
    "                backward_extrap_start =all_measures[0]\n",
    "            #end on first beat of this block\n",
    "            backward_extrap_end =    x[blocks[i][0]]\n",
    "            \n",
    "            backward_start_idx = all_measures.index(backward_extrap_start)\n",
    "            backward_end_idx = all_measures.index(backward_extrap_end)\n",
    "            \n",
    "            \n",
    "            backward_x = all_measures[backward_start_idx: backward_end_idx+1] #include end\n",
    "            backward_y = f(backward_x)\n",
    "            print(\"In backward extrapolation: mapped\", backward_x, \"to\", backward_y)\n",
    "            backward_y = backward_y - backward_y[0]\n",
    "            \n",
    "            backward_extrapolation_lst.append({'startval':backward_start_idx,\n",
    "                                               'endval':backward_end_idx , \n",
    "                                               'y':backward_y})\n",
    " \n",
    "        print(\"\\n\\n@@@@@@@@@@@@@@@\\n Part 3: filling in long NAN values\")\n",
    "\n",
    "        '''\n",
    "        Decide final extrapolated values\n",
    "        '''\n",
    "        #Fill beginning and ending values\n",
    "        beginning = backward_extrapolation_lst[0]  \n",
    "        print('beginning dct', beginning)\n",
    "        # TODO: this should move backward from last existing value\n",
    "        extrap_df[v].loc[beginning['startval']: beginning['endval']] = (\n",
    "            extrap_df[v].loc[beginning['endval']]- beginning['y'][-1])+ beginning['y']\n",
    "        \n",
    "        print(extrap_df[v].loc[beginning['endval']]- beginning['y'][-1])\n",
    "        print(beginning['y'])\n",
    "        backward_extrapolation_lst.pop(0)\n",
    "        \n",
    "        ending = forward_extrapolation_lst[-1] \n",
    "        #for ending values, add differences on last existing value\n",
    "        extrap_df[v].loc[ending['startval']: ending['endval']] = ending['y'] +extrap_df[v].loc[ending['startval']]\n",
    "        forward_extrapolation_lst.pop(-1)      \n",
    "        \n",
    "        print(\"dataframe\\n\", extrap_df[v])\n",
    "        \n",
    "        print(\"\\n\\n$$$$$$$$$$\\nExtrapolating long rests and moving forward\\n\")\n",
    "        \n",
    "        \n",
    "        print('backward extrap info\\n', backward_extrapolation_lst[0:3])\n",
    "        print('forward extrap info\\n', forward_extrapolation_lst[0:3])\n",
    "        #Rest of long rests:\n",
    "        for i in range(len(backward_extrapolation_lst)):\n",
    "            print(\"SHOULD BE SAME\")\n",
    "            print(\"starts\", backward_extrapolation_lst[i]['startval'], \n",
    "                 forward_extrapolation_lst[i]['startval'])\n",
    "            print(\"ends\", backward_extrapolation_lst[i]['endval'], \n",
    "                 forward_extrapolation_lst[i]['endval'])\n",
    "            \n",
    "            forward_y = forward_extrapolation_lst[i]['y']\n",
    "            backward_y = backward_extrapolation_lst[i]['y']\n",
    "            start_idx = forward_extrapolation_lst[i]['startval']\n",
    "            end_idx = forward_extrapolation_lst[i]['endval']\n",
    "            start_frame = extrap_df[v].loc[start_idx]\n",
    "            end_frame = extrap_df[v].loc[end_idx]\n",
    "            print(\"start frame\", start_frame)\n",
    "            print(\"end_frame\", end_frame)\n",
    "            '''\n",
    "            Option 1: average:  \n",
    "            '''\n",
    "            forward_y_arr = np.array(forward_y)\n",
    "            print(\"FORWARD:\\n\", forward_y_arr)\n",
    "            backward_y_arr = np.array(backward_y)\n",
    "            print(\"Backward:\\n\", backward_y_arr)\n",
    "            if method=='avg':\n",
    "                print(\"forward_y\", forward_y )\n",
    "                print(\"backward_y\",backward_y)\n",
    "                y_extrap = (forward_y_arr + backward_y_arr ) /2\n",
    "          \n",
    "            #Option 2: smooth interpolation\n",
    "          \n",
    "            elif method=='smooth_interp':\n",
    "                forward_y_weights = np.linspace( 1,0, len(forward_y_arr))\n",
    "                backward_y_weights = 1-forward_y_weights\n",
    "                print(\"forward_y_weights\", forward_y_weights)\n",
    "                print(\"backward_y_weights\", backward_y_weights)\n",
    "                print(\"sum weight forward\", forward_y_weights * np.diff(forward_y_arr, prepend=0))\n",
    "                print(\"sum_weight_backward\", backward_y_weights*np.diff(backward_y_arr, prepend=0)  )              \n",
    "                y_diffs = (forward_y_weights * np.diff(forward_y_arr, prepend=0)\n",
    "                            + backward_y_weights*np.diff(backward_y_arr, prepend=0))\n",
    "                y_extrap = np.cumsum(y_diffs)\n",
    "                \n",
    "                print(\"in method, extrapolated vals are\\n\", y_extrap)\n",
    "            #add to last value\n",
    "            y_extrap = y_extrap + start_frame\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            Perform assignment of nan values and shifting of values after\n",
    "            '''\n",
    "       \n",
    "            #assign extrapolation to NAN values\n",
    "            print(\"y_extrap\\n\", y_extrap)\n",
    "            print(\"putting values at \", extrap_df[v].loc[start_idx: end_idx])\n",
    "            extrap_df[v].loc[start_idx: end_idx] = y_extrap\n",
    "            print(\"df\\n\", extrap_df[v])\n",
    "            #shift forward previous values\n",
    "            shift = extrap_df[v].loc[end_idx]-end_frame\n",
    "            print(\"next section should shift by \", shift)\n",
    "            if i< len(backward_extrapolation_lst) - 1: \n",
    "                next_start_idx = forward_extrapolation_lst[i+1]['startval']\n",
    "            else: \n",
    "                next_start_idx = len(all_measures)\n",
    "                \n",
    "            print(\"inserting into\\n\", extrap_df[v].loc[end_idx: next_start_idx])\n",
    "            print(\"end idx\", end_idx)\n",
    "            print(\"next start idx\", next_start_idx)\n",
    "            extrap_df[v].loc[end_idx+1: next_start_idx] = extrap_df[v].loc[end_idx+1: next_start_idx]+shift\n",
    "        extrap_df[v] = extrap_df[v]- extrap_df[v].loc[0]\n",
    "\n",
    "    return extrap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_measures = list(comb_df['eval_measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_comb_df = make_extrapolate_df(comb_df, df_dct, all_measures, method = 'avg')\n",
    "filled_comb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-walker",
   "metadata": {},
   "source": [
    "Check interpolation quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(filled_comb_df['eval_measure'], filled_comb_df['clarinet_2'], 'bo')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-egypt",
   "metadata": {},
   "source": [
    "# Other utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_new_stft(df_dct, optimized_df, instrument_lst):\n",
    "    df_dct1 = df_dct.copy()\n",
    "    for v in instrument_lst:\n",
    "\n",
    "        frames_df=  optimized_df[['eval_measure']].copy()\n",
    "        frames_df['New STFT frames']=optimized_df[v].astype(int) #was hardcoded oboe_1\n",
    "        frames_df[\"new_times\"] = stft_frames_to_seconds(frames_df['New STFT frames'])\n",
    "        frames_df= frames_df.set_index('eval_measure')\n",
    "\n",
    "        #join\n",
    "        df_dct1[v]=df_dct[v].set_index('eval_measure').join(frames_df)\n",
    "    return df_dct1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tempos(x0, x_gd, del_m_series, start=0, stop=None, ylow=None, yhigh=None, show_rates=False):\n",
    "    for p in range(n_p):\n",
    "\n",
    "        d = np.diff(x0[:,p])\n",
    "\n",
    "\n",
    "        e = np.diff(x_gd[:,p])\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(instrument_lst[p])\n",
    "        plt.plot((d/del_m_series)[start:stop], label='old tempo')\n",
    "        plt.plot((e/del_m_series)[start:stop], label = 'new ')\n",
    "        if show_rates == True:\n",
    "            print(\"Rate values\", (e/del_m_series)[start:stop])\n",
    "        plt.ylim([ylow, yhigh])\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_parsed_leader1 = [['clarinet_1', (0,5)], \n",
    "                      ['oboe_1',(5,8)],\n",
    "                      ['oboe_2', (8,9)],\n",
    "                      ['horn_in_e_1', (9,13)],\n",
    "                     [ 'bassoon_1',(13,14.5)],\n",
    "                     [ 'horn_in_e_1',(14.5, 16.5)],\n",
    "                     [ 'oboe_2', (16.5,17)],\n",
    "                      ['horn_in_e_1',(17, 17.5)],\n",
    "                      ['oboe_1',(17.5, 18)],\n",
    "                      ['horn_in_e_1',(18, 18.5)],  \n",
    "                      ['clarinet_2',(18.5, 19)],\n",
    "                      ['horn_in_e_1',(19, 19.5)],\n",
    "                      ['clarinet_1',(19.5, 20)],\n",
    "                      ['bassoon_2',(20, 20.5)],\n",
    "                      ['bassoon_1',(20.5, 21.5)],\n",
    "                      ['horn_in_e_1',(21.5, 22.5)],\n",
    "                      ['oboe_1',(22.5,24)],\n",
    "                      ['bassoon_1',(24, 25)],\n",
    "                      ['oboe_1',(25, 26.5)],\n",
    "                      ['clarinet_1',(26.5, 30.5)],\n",
    "                      ['oboe_1',(30.5,38)],\n",
    "                      ['clarinet_1',(38, 39.5)],\n",
    "                      ['oboe_1',(39.5, 43)], \n",
    "                      ['clarinet_1',(43,45.5)],\n",
    "                      ['clarinet_2',(45.5, 46.5)],\n",
    "                      ['oboe_1',(46.5, 48)],\n",
    "                      ['horn_in_e_2',(48, 49)],\n",
    "                      ['clarinet_2',(49, 50)],\n",
    "                      ['bassoon_1',(50, 51)],\n",
    "                      ['horn_in_e_2',(51, 52)],\n",
    "                      ['clarinet_2',(52, 53)],\n",
    "                      ['bassoon_1',(53, 54)],                      \n",
    "                      ['horn_in_e_2',(54, 55)],\n",
    "                      ['clarinet_2',(55, 56)],\n",
    "                      ['bassoon_1',(56, 57)], \n",
    "                      ['clarinet_2',(57, 59)], \n",
    "                      ['oboe_1',(59, 60)], \n",
    "                      ['horn_in_e_2',(60, 60.5)],\n",
    "                      ['clarinet_1',(60.5, 61)], \n",
    "                      ['horn_in_e_1',(61, 61.5)],\n",
    "                      ['clarinet_2',(61.5, 62)],\n",
    "                      ['horn_in_e_1',(62, 62.5)],\n",
    "                      ['oboe_1',(62.5, 63)],\n",
    "                      ['horn_in_e_1',(63, 63.5)],\n",
    "                      ['oboe_2',(63.5, 64)],\n",
    "                      ['bassoon_2',(64, 64.5)],\n",
    "                      ['bassoon_1',(64.5, 65.5)],\n",
    "                      ['clarinet_1',(65.5, 66.5)],\n",
    "                      ['clarinet_2',(66.5, 67.5)],\n",
    "                      ['oboe_2',(67.5, 69)],\n",
    "                      ['clarinet_2',(69, 70)], \n",
    "                      ['clarinet_1',(70, 71)], \n",
    "                      ['horn_in_e_2',(71, 72)],\n",
    "                      ['clarinet_1',(72, 74.5)],\n",
    "                      ['oboe_1',(74.5, 78)],\n",
    "                      ['clarinet_1',(78, 79.5)],\n",
    "                      ['oboe_1',(79.5, 80)],\n",
    "                      ['bassoon_1',(80, 82.5)],\n",
    "                      ['clarinet_1',(82.5, 91)]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for key in hand_parsed_leader1 :\n",
    "    if key[0] not in instrument_lst:\n",
    "        print(key, hand_parsed_leader[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-participant",
   "metadata": {},
   "source": [
    "# Follow the Leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def follow_leader_manual(hand_parsed_lst, filled_comb_df, instrument_lst):\n",
    "    prev_val=0\n",
    "    hand_df = filled_comb_df.copy()\n",
    "    \n",
    "    for i in range(len(hand_parsed_lst)):\n",
    "        #current block\n",
    "        leader = hand_parsed_lst[i]\n",
    "        instr=leader[0]\n",
    "        lims=leader[1]\n",
    "\n",
    "        print('lims[0] is ', lims[0])\n",
    "\n",
    "        cond = ((filled_comb_df['eval_measure']<=lims[1])&\n",
    "                        (lims[0] <=filled_comb_df['eval_measure']) )\n",
    "\n",
    "        raw_leader_times = (filled_comb_df[instr]).loc[cond]\n",
    "        end_idx =  raw_leader_times.head(1).index[0]\n",
    "        print('end_idx',end_idx)\n",
    "        #calculate shift\n",
    "        original_start = filled_comb_df[instr].iloc[end_idx]\n",
    "        print('origianl start', original_start)\n",
    "\n",
    "        beg = hand_df[instr].iloc[end_idx]\n",
    "        move = beg - original_start\n",
    "        print('beginning is ', beg)\n",
    "        print(\"prev val is \", prev_val)\n",
    "        print('move is ', move)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "        print(\"prev val is \", prev_val)\n",
    "        leader_times = raw_leader_times + move\n",
    "        leader_tiled =np.tile(np.array(leader_times), (len(instrument_lst)+1,1)).T\n",
    "        print(leader_times)\n",
    "        \n",
    "        \n",
    "        #previous end \n",
    "\n",
    "\n",
    "        hand_df.loc[cond]= leader_tiled\n",
    "\n",
    "        #find previous value \n",
    "    hand_df['eval_measure']= filled_comb_df['eval_measure']\n",
    "    return hand_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_constant = 60000/filled_comb_df[instrument_lst].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_fc_df = filled_comb_df[instrument_lst]*norm_constant\n",
    "normalized_fc_df['eval_measure']= filled_comb_df['eval_measure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "times_manual = follow_leader_manual(hand_parsed_leader1, normalized_fc_df, instrument_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, times_manual, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"whole_audio/mozart_follow_leader_hp1.wav\", sr_ensemble, stretched_full_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-method",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "- everything starts at same tempo. \n",
    "- next timepoint is a * group_pred_position + b * self_desired_position + c* value interpolated by current tempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-alignment",
   "metadata": {},
   "source": [
    "##### Slow down phenomena\n",
    "\n",
    "\n",
    "- Why? \n",
    "- If one instrument takes time then speeds up, other instruments will react to the slow down, slowing down the average tempo. When the original instruments speeds up again, they are influenced by the new slower average tempo and don't gain the time back\n",
    "- This leads to negative feedback loop that makes everything go slower and slower\n",
    "\n",
    "\n",
    "How to fix?\n",
    "- Steady leaders/leader\n",
    "    - \"Accompaniment\" instruments listen only to solid beat instrument, this way they are not swayed by soloists\n",
    "    - \"Solo\" instruments listen to accomapniment instrumnets to stay generally on the beat\n",
    "    \n",
    "- Tempo correction term\n",
    "    - Part of next step depends on a target tempo, preventing excessive slowdowns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-complaint",
   "metadata": {},
   "source": [
    "$t_{j+1} = t_{i,j}+ w_{tog}G_{tog}(j) + w_{self}G_{self}(i,j) + w_{tempo}G_{tempo}(j)$, \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$G_{tog}(j)= (m_{j+1}-m_{j})\\frac{1}{n_p}\\sum^{n_p}_{i=1}\\frac{t_{i, j}-t_{i,j-1}}{m_j-m_{j-1}}$\n",
    "\n",
    "$G_{self}(i,j)= \\frac{t^0_{i,j+1}-t^0_{i,j}}{t^0_{i,j}-t^0_{i, j-1}}(t_{i,j}-t_{i, j-1})$\n",
    "\n",
    "$G_{tempo}(j)=(m_{j+1}-m_{j})R_{j}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs normalized timing df where 1st beat is the same length used for simulations\n",
    "def normalize_df(input_df, tempo):\n",
    "    df = input_df.copy()\n",
    "    #initialize\n",
    "    m0 = df.loc[0]\n",
    "    m1 = df.loc[1]\n",
    "    diff0 = m1-m0\n",
    "    #switch with frames_per_measure later\n",
    "    first_beatlen = diff0['eval_measure']* tempo\n",
    "    #What multiple is needed to normalize tempo for all parts\n",
    "    tempo_multiple = diff0/first_beatlen\n",
    "    #normalize tempo by matching length of first note\n",
    "    df[instrument_lst]=(df / tempo_multiple)[instrument_lst]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-indiana",
   "metadata": {},
   "source": [
    "## Simulation versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-communication",
   "metadata": {},
   "source": [
    "Old version: does not allow for target tempo loss or variable listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_performance(input_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, \n",
    "                         tempo,catch_reverse=True):\n",
    "\n",
    "    df = input_df.copy()\n",
    "    #initialize\n",
    "    m0 = df.loc[0]\n",
    "    m1 = df.loc[1]\n",
    "    diff0 = m1-m0\n",
    "    #switch with frames_per_measure later\n",
    "    first_beatlen = diff0['eval_measure']* tempo\n",
    "    #What multiple is needed to normalize tempo for all parts\n",
    "    tempo_multiple = diff0/first_beatlen\n",
    "    #normalize tempo by matching length of first note\n",
    "    df[instrument_lst]=(df / tempo_multiple)[instrument_lst]\n",
    "    norm_df = df.copy()\n",
    "    #print(\"df normalized\\n\", df)\n",
    "    #calculate differences between relative note beats\n",
    "    #access i-2 th element for \n",
    "    df_diff = df.diff().dropna().reset_index(drop=True)\n",
    "\n",
    "    x1 = df_diff.loc[1:n_b-2].reset_index(drop=True)\n",
    "\n",
    "    x2 = df_diff.loc[0:n_b-3]      \n",
    "    #ratio between length of adjacent notes \n",
    "    ratios = x1.divide(x2) \n",
    "    #return ratios\n",
    "    #print('ratios are\\n', ratios)\n",
    "    #Loop to update\n",
    "    i = 2\n",
    "\n",
    "    while i < n_b:\n",
    "        \n",
    "        print(\"\\n***ON NOTE: \", i)\n",
    "\n",
    "        #prev values are all updated\n",
    "        prev_del = df.loc[i-1] - df.loc[i-2]\n",
    "        prev_beatlen = prev_del['eval_measure']\n",
    "        prev_diffs = prev_del[instrument_lst]\n",
    "        \n",
    "        #df.loc[i] is not yet updated\n",
    "        cur_del = df.loc[i] - df.loc[i-1]\n",
    "        cur_beatlen = cur_del['eval_measure']\n",
    "\n",
    "        '''\n",
    "        calculate average predicted location based on other parts\n",
    "        '''\n",
    "        prev_rates = prev_diffs/prev_beatlen\n",
    "        avg_prev_location = np.mean(df[instrument_lst].loc[i-1])\n",
    "\n",
    "        avg_trajectory_loc = (cur_beatlen *sum(prev_rates)/(n_p)  \n",
    "                    +  avg_prev_location)\n",
    "        \n",
    "        print(\"\\ntrajectory considering only group:\", avg_trajectory_loc )\n",
    "\n",
    "        '''\n",
    "        location of next note based on original part's ratio\n",
    "        '''\n",
    "        #print('previous location should have updated\\n', df[instrument_lst].loc[i-1])\n",
    "        self_trajectory_loc = (df[instrument_lst].loc[i-1]+\n",
    "                ratios[instrument_lst].loc[i-2]*prev_diffs )\n",
    "        #print('ratio is \\n',  ratios[instrument_lst].loc[i-2])\n",
    "        #print(\"prev diffs are\\n\", prev_diffs)\n",
    "        print(\"\\ntrajectory considering only self:\\n\", self_trajectory_loc )\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        perform update\n",
    "        '''\n",
    "        \n",
    "        #print(\"ABOUT TO UPDATE\\n\")\n",
    "        #print(\"weighted self loc\\n\",self_weight.loc[i] * self_trajectory_loc )\n",
    "        #print(\"weighted avg loc\\n\",avg_weight.loc[i] * avg_trajectory_loc)\n",
    "        df.loc[i][instrument_lst] = (self_weight.loc[i] * self_trajectory_loc \n",
    "                                     + avg_weight.loc[i] * avg_trajectory_loc) \n",
    "\n",
    "        print('\\nfinal trajectory:\\n',df.loc[i])\n",
    "        print(\"\\nOriginal location\\n\", norm_df.loc[i])\n",
    "        '''\n",
    "        Ensure all change is positive\n",
    "        '''\n",
    "        negatives = df.loc[i]<df.loc[i-1]\n",
    "        #print(\"negatives?\", sum(negatives))\n",
    "        if catch_reverse:\n",
    "\n",
    "            df.loc[i][negatives]= df.loc[i-1]#ensure no negatives \n",
    "\n",
    "\n",
    "        i +=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-department",
   "metadata": {},
   "source": [
    "# testing\n",
    "\n",
    "- If a part starts slow, gets faster, then gets slower, the total time will exceed the average time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-february",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#normal, fast then slow \n",
    "x=np.array([[1., 2., 3., 4., 5.],\n",
    "           [0, 1, 1.5, 2, 4],\n",
    "           [1., 2.1, 3.3, 4.4, 5.5]])\n",
    "measure = np.array([1,1.25, 1.5, 1.75, 2. ])\n",
    "columns = ['t1', 't2', 't3']\n",
    "\n",
    "test_df = pd.DataFrame(x.T, columns = columns)\n",
    "\n",
    "\n",
    "test_df['eval_measure']= measure\n",
    "test_df = test_df - test_df.loc[0]\n",
    "\n",
    "\n",
    "#sim parameters \n",
    "time_per_measure = 4\n",
    "n_b=len(test_df)\n",
    "n_p = 3\n",
    "\n",
    "self_weight = test_df[columns]*0+0.5\n",
    "avg_weight = test_df[columns]*0+0.5\n",
    "other_instrument_df = {'t1':['t2', 't3'],\n",
    "                     't2':['t1', 't3'],\n",
    "                      't3':['t1', 't2']}\n",
    "instrument_lst = columns\n",
    "\n",
    "#run sim\n",
    "new_df = simulate_performance(test_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, \n",
    "                         time_per_measure,False)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_df(test_df, time_per_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-steel",
   "metadata": {},
   "source": [
    "### Plot tempos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rates(input_df):\n",
    "    diff_df = input_df.diff()\n",
    "    plt.figure()\n",
    "\n",
    "    for instr in instrument_lst:\n",
    "        plt.title(\"Tempo fluctuation: \"+instr)\n",
    "        plt.plot((diff_df['eval_measure']/diff_df[instr]).iloc[:-1], alpha=.5,label=instr)\n",
    "        plt.legend()    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-lender",
   "metadata": {},
   "source": [
    "# Variable listening version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes only 1 set of listened instruments\n",
    "def simulate_performance_flex(input_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=False, tempo_correction=False,\n",
    "                             const=2): #const is reverse addition\n",
    "\n",
    "    df = input_df.copy()\n",
    "    #initialize\n",
    "    m0 = df.loc[0]\n",
    "    m1 = df.loc[1]\n",
    "    diff0 = m1-m0\n",
    "    #switch with frames_per_measure later\n",
    "    first_beatlen = diff0['eval_measure']* tempo\n",
    "    #What multiple is needed to normalize tempo for all parts\n",
    "    tempo_multiple = diff0/first_beatlen\n",
    "    #normalize tempo by matching length of first note\n",
    "    df[instrument_lst]=(df / tempo_multiple)[instrument_lst]\n",
    "    norm_df = df.copy()\n",
    "    #print(\"df normalized\\n\", df)\n",
    "    #calculate differences between relative note beats\n",
    "    #access i-2 th element for \n",
    "    df_diff = df.diff().dropna().reset_index(drop=True)\n",
    "\n",
    "    x1 = df_diff.loc[1:n_b-2].reset_index(drop=True)\n",
    "\n",
    "    x2 = df_diff.loc[0:n_b-3]      \n",
    "    #ratio between length of adjacent notes \n",
    "    ratios = x1.divide(x2) \n",
    "    #return ratios\n",
    "    #print('ratios are\\n', ratios)\n",
    "    #Loop to update\n",
    "    i = 2\n",
    "\n",
    "    while i < n_b:\n",
    "        \n",
    "        print(\"\\n***ON NOTE: \", i)\n",
    "\n",
    "        #prev values are all updated\n",
    "        prev_del = df.loc[i-1] - df.loc[i-2]\n",
    "        prev_beatlen = prev_del['eval_measure']\n",
    "        prev_diffs = prev_del[instrument_lst]\n",
    "        \n",
    "        #df.loc[i] is not yet updated\n",
    "        cur_del = df.loc[i] - df.loc[i-1]\n",
    "        cur_beatlen = cur_del['eval_measure']\n",
    "        \n",
    "        '''\n",
    "        location of next note based on original part's ratio\n",
    "        '''\n",
    "        #print('previous location should have updated\\n', df[instrument_lst].loc[i-1])\n",
    "        self_trajectory_loc = (df[instrument_lst].loc[i-1]+\n",
    "                ratios[instrument_lst].loc[i-2]*prev_diffs )\n",
    "        #print('ratio is \\n',  ratios[instrument_lst].loc[i-2])\n",
    "        #print(\"prev diffs are\\n\", prev_diffs)\n",
    "        print(\"\\ntrajectory considering only self:\\n\", self_trajectory_loc )\n",
    "        \n",
    "        \n",
    "\n",
    "        '''\n",
    "        calculate average predicted location based on other parts\n",
    "        '''\n",
    "        prev_rates = prev_diffs/prev_beatlen\n",
    "        avg_trajectory_loc= prev_rates.copy()#just to initalize, do this better\n",
    "        #who is listening to who?\n",
    "        for instr in listens_dct:\n",
    "            listen_instrs = listens_dct[instr]\n",
    "            if len(listen_instrs)>0:\n",
    "                avg_prev_location = np.mean(df[listen_instrs].loc[i-1])\n",
    "\n",
    "                listen_avg_trajectory_loc = (cur_beatlen *\n",
    "                                             sum(prev_rates[listen_instrs])/(len(listen_instrs))  \n",
    "                            +  avg_prev_location)\n",
    "                avg_trajectory_loc[instr]=listen_avg_trajectory_loc\n",
    "            #if not listening, just stay own course\n",
    "            else:\n",
    "                avg_trajectory_loc[instr]=self_trajectory_loc[instr]\n",
    "\n",
    "        \n",
    "        print(\"\\ntrajectory considering only group:\", avg_trajectory_loc )\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        Ascertain Tempo-based trajectory\n",
    "        '''\n",
    "        if tempo_correction:\n",
    "            tempo_trajectory_loc = df[instrument_lst].loc[i-1] + tempo * cur_beatlen\n",
    "\n",
    "            print('tempo_trajectory_loc', tempo_trajectory_loc)\n",
    "            weighted_tempo = tempo_weight[i]* tempo_trajectory_loc\n",
    "        else:\n",
    "            weighted_tempo = 0\n",
    "            \n",
    "        \n",
    "        '''\n",
    "        Put it together\n",
    "        '''\n",
    "\n",
    "        #update\n",
    "        df.loc[i][instrument_lst] = (self_weight.loc[i] * self_trajectory_loc \n",
    "                                     + avg_weight.loc[i] * avg_trajectory_loc\n",
    "                                     +weighted_tempo) \n",
    "\n",
    "        print('\\nfinal trajectory:\\n',df.loc[i])\n",
    "        print(\"\\nOriginal location\\n\", norm_df.loc[i])\n",
    "        '''\n",
    "        Ensure all change is positive\n",
    "        '''\n",
    "        negatives = df.loc[i]<df.loc[i-1]\n",
    "        #print(\"negatives?\", sum(negatives))\n",
    "        if catch_reverse:\n",
    "\n",
    "            df.loc[i][negatives]= df.loc[i-1]+ const#ensure no negatives \n",
    "\n",
    "\n",
    "        i +=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-workstation",
   "metadata": {},
   "source": [
    "## Test 0: Test with just bassoon 1 and clarinet 1\n",
    "- test performed with original algorithm\n",
    "- they are listening to eachother, shows slowdown clearly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-anthropology",
   "metadata": {},
   "source": [
    "Why does simulation slow down?\n",
    "\n",
    "Clarinet 1 takes time, or goes slower than expected. Normally, bassoon 1 would not respond to clarinet 1, but it ends up slowing down in the simulation because they are listening to eachother 50/50. Can see this as early as note 9 in the lim simualtion. People tend to take time at the end of phrases, and between \"stay constant\" and \"ritard\", the result will be \"slightly slower\".\n",
    "\n",
    "To fix this: We want the \"engine\" listen selectively to other engine parts. Free lines should be about 50/50, staying with the group but doing their own thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_lst = [\"clarinet_1\", \n",
    "                  \"bassoon_1\"]\n",
    "lim_df = filled_comb_df[['eval_measure', 'clarinet_1', 'bassoon_1']]\n",
    "n_b = len(lim_df)\n",
    "n_p = len(instrument_lst)\n",
    "#self contribution\n",
    "self_weight = lim_df*0+.5\n",
    "avg_weight = 1-self_weight\n",
    "sim_df = simulate_performance(lim_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst,  tempo, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-light",
   "metadata": {},
   "source": [
    "### Test 1: clarinet 1, oboe1 as solo, clarinet2, bassoon1 as acc. Just first 16 bars\n",
    "\n",
    "If only engine instruments listen to eachother, at .5 there is still a little slowdown - guessing bc they are note perfectly steady. \n",
    "\n",
    "At .8 there is speed up. \n",
    "\n",
    "If following clarinet1 there is slowdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_acc_df = filled_comb_df[['eval_measure', 'oboe_1', \n",
    "                                   'clarinet_1', 'clarinet_2',\n",
    "                                   'bassoon_1']]\n",
    "\n",
    "solo_acc_df = solo_acc_df.loc[solo_acc_df['eval_measure']<17]\n",
    "\n",
    "instrument_lst=['oboe_1',  'clarinet_1', 'clarinet_2',\n",
    "                                   'bassoon_1']\n",
    "n_b=len(solo_acc_df)\n",
    "#self contribution\n",
    "self_weight = solo_acc_df*0+.8\n",
    "avg_weight = 1-self_weight\n",
    "\n",
    "#define 'listens to'\n",
    "clarinet_1_listens= ['clarinet_1','clarinet_2', 'bassoon_1']\n",
    "clarinet_2_listens= ['clarinet_2', 'bassoon_1']\n",
    "bassoon_1_listens = ['clarinet_2', 'bassoon_1']\n",
    "oboe_1_listens=['oboe_1','clarinet_2', 'bassoon_1']\n",
    "\n",
    "listens_dct = {'oboe_1':oboe_1_listens, \n",
    "              'clarinet_1':clarinet_1_listens,\n",
    "              'bassoon_1': bassoon_1_listens,\n",
    "               'clarinet_2':clarinet_2_listens}\n",
    "\n",
    "simulate_performance_flex(solo_acc_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-shield",
   "metadata": {},
   "source": [
    "## Experiment 1: listen to \"backbeat\" instruments\n",
    "\n",
    "- One 'solid beat' instrument, bassoon 2, ignores all other instruments\n",
    "- \"Accompaniment\" instruments listen only to solid beat instrument, this way they are not swayed by soloists\n",
    "- \"Solo\" instruments listen to accomapniment instrumnets to stay generally on the beat\n",
    "\n",
    "- In variation where there is no solid beat, interpretation slows down when assumptions break\n",
    "\n",
    "\n",
    "- Benefit: high amount of specificity possible\n",
    "- Drawback: need to choose single solid beat instrument or a combination that does not slow down, because slow downs feed into eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_acc_df = filled_comb_df.copy()\n",
    "\n",
    "#solo_acc_df = solo_acc_df.loc[solo_acc_df['eval_measure']<17]\n",
    "\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_b=len(solo_acc_df)\n",
    "#self contribution\n",
    "self_weight = solo_acc_df*0+.5\n",
    "avg_weight = 1-self_weight\n",
    "\n",
    "tempo=seconds_to_stft_frames(4)\n",
    "\n",
    "#define 'listens to'\n",
    "oboe_1_listens=[  'oboe_2','clarinet_1', 'clarinet_2',  'horn_in_e_1', 'horn_in_e_2',\n",
    "                'bassoon_1','bassoon_2', ]\n",
    "\n",
    "clarinet_1_listens= [ 'oboe_1', 'oboe_2', 'clarinet_2',  'horn_in_e_1', 'horn_in_e_2',\n",
    "                'bassoon_1','bassoon_2', ]\n",
    "\n",
    "bassoon_1_listens = [ 'oboe_1', 'oboe_2','clarinet_1', 'clarinet_2',   'horn_in_e_2',\n",
    "                'bassoon_2', ]\n",
    "\n",
    "horn_1_listens = [ 'oboe_1', 'oboe_2','clarinet_1', 'clarinet_2',  'horn_in_e_1', 'horn_in_e_2',\n",
    "                'bassoon_1','bassoon_2', ]\n",
    "\n",
    "oboe_2_listens = [ 'clarinet_2',  \n",
    "                'bassoon_2', 'horn_in_e_2']\n",
    "\n",
    "clarinet_2_listens= [ 'oboe_2',  \n",
    "                'bassoon_2', 'horn_in_e_2']\n",
    "\n",
    "bassoon_2_listens = []\n",
    "\n",
    "horn_2_listens = [ 'clarinet_2',  \n",
    "                'bassoon_2', 'oboe_2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-penny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in listens dct\n",
    "\n",
    "def simulate_performance_listens(input_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=False, tempo_correction=False,\n",
    "                             const=2): #const is reverse addition\n",
    "\n",
    "    df = input_df.copy()\n",
    "    #initialize\n",
    "    m0 = df.loc[0]\n",
    "    m1 = df.loc[1]\n",
    "    diff0 = m1-m0\n",
    "    #switch with frames_per_measure later\n",
    "    first_beatlen = diff0['eval_measure']* tempo\n",
    "    #What multiple is needed to normalize tempo for all parts\n",
    "    tempo_multiple = diff0/first_beatlen\n",
    "    #normalize tempo by matching length of first note\n",
    "    df[instrument_lst]=(df / tempo_multiple)[instrument_lst]\n",
    "    norm_df = df.copy()\n",
    "    #print(\"df normalized\\n\", df)\n",
    "    #calculate differences between relative note beats\n",
    "    #access i-2 th element for \n",
    "    df_diff = df.diff().dropna().reset_index(drop=True)\n",
    "\n",
    "    x1 = df_diff.loc[1:n_b-2].reset_index(drop=True)\n",
    "\n",
    "    x2 = df_diff.loc[0:n_b-3]      \n",
    "    #ratio between length of adjacent notes \n",
    "    ratios = x1.divide(x2) \n",
    "    #return ratios\n",
    "    #print('ratios are\\n', ratios)\n",
    "    #Loop to update\n",
    "    i = 2\n",
    "\n",
    "    while i < n_b:\n",
    "        \n",
    "        print(\"\\n***ON NOTE: \", i)\n",
    "\n",
    "        #prev values are all updated\n",
    "        prev_del = df.loc[i-1] - df.loc[i-2]\n",
    "        prev_beatlen = prev_del['eval_measure']\n",
    "        prev_diffs = prev_del[instrument_lst]\n",
    "        \n",
    "        #df.loc[i] is not yet updated\n",
    "        cur_del = df.loc[i] - df.loc[i-1]\n",
    "        cur_beatlen = cur_del['eval_measure']\n",
    "        \n",
    "        '''\n",
    "        location of next note based on original part's ratio\n",
    "        '''\n",
    "        #print('previous location should have updated\\n', df[instrument_lst].loc[i-1])\n",
    "        self_trajectory_loc = (df[instrument_lst].loc[i-1]+\n",
    "                ratios[instrument_lst].loc[i-2]*prev_diffs )\n",
    "        #print('ratio is \\n',  ratios[instrument_lst].loc[i-2])\n",
    "        #print(\"prev diffs are\\n\", prev_diffs)\n",
    "        print(\"\\ntrajectory considering only self:\\n\", self_trajectory_loc )\n",
    "        \n",
    "        \n",
    "\n",
    "        '''\n",
    "        calculate average predicted location based on other parts\n",
    "        '''\n",
    "        prev_rates = prev_diffs/prev_beatlen\n",
    "        avg_trajectory_loc= prev_rates.copy()#just to initalize, do this better\n",
    "        #who is listening to who?\n",
    "        for instr in listens_dct:\n",
    "            indicator_row = (listens_dct[instr].loc[i])[instrument_lst]\n",
    "            listen_instrs = list(indicator_row.loc[indicator_row>0].axes[0])\n",
    "            if len(listen_instrs)>0:\n",
    "                avg_prev_location = np.mean(df[listen_instrs].loc[i-1])\n",
    "\n",
    "                listen_avg_trajectory_loc = (cur_beatlen *\n",
    "                                             sum(prev_rates[listen_instrs])/(len(listen_instrs))  \n",
    "                            +  avg_prev_location)\n",
    "                avg_trajectory_loc[instr]=listen_avg_trajectory_loc\n",
    "            #if not listening, just stay own course\n",
    "            else:\n",
    "                avg_trajectory_loc[instr]=self_trajectory_loc[instr]\n",
    "\n",
    "        \n",
    "        print(\"\\ntrajectory considering only group:\\n\", avg_trajectory_loc )\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        Ascertain Tempo-based trajectory\n",
    "        '''\n",
    "        if tempo_correction:\n",
    "            tempo_trajectory_loc = df[instrument_lst].loc[i-1] + tempo * cur_beatlen\n",
    "\n",
    "            print('tempo_trajectory_loc\\n', tempo_trajectory_loc)\n",
    "            weighted_tempo = tempo_weight[i]* tempo_trajectory_loc\n",
    "        else:\n",
    "            weighted_tempo = 0\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        '''\n",
    "        Put it together\n",
    "        '''\n",
    "\n",
    "        #update\n",
    "        df.loc[i][instrument_lst] = (self_weight.loc[i] * self_trajectory_loc \n",
    "                                     + avg_weight.loc[i] * avg_trajectory_loc\n",
    "                                     +weighted_tempo) \n",
    "\n",
    "        print('\\nfinal trajectory:\\n',df.loc[i])\n",
    "        print(\"\\nOriginal location\\n\", norm_df.loc[i])\n",
    "        '''\n",
    "        Ensure all change is positive\n",
    "        '''\n",
    "        negatives = df.loc[i]<df.loc[i-1]\n",
    "        #print(\"negatives?\", sum(negatives))\n",
    "        if catch_reverse:\n",
    "\n",
    "            df.loc[i][negatives]= df.loc[i-1]+ const#ensure no negatives \n",
    "\n",
    "\n",
    "        i +=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-adoption",
   "metadata": {},
   "source": [
    "# Experiment: full hand specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_weight=.7\n",
    "acc_weight=.2\n",
    "rest_weight=.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_weight = filled_comb_df*0+.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "          self_weight, solo_weight, acc_weight, rest_weight):\n",
    "    \n",
    "\n",
    "\n",
    "    for instr in solo:\n",
    "        #deal with listens dct\n",
    "        ((listens_dct[instr][instr]).loc[start_idx:stop_idx+1])=0\n",
    "        for rest_instr in resting:\n",
    "            ((listens_dct[instr][rest_instr]).loc[start_idx:stop_idx+1])=0\n",
    "\n",
    "\n",
    "    for instr in acc:\n",
    "        ((listens_dct[instr][instr]).loc[start_idx:stop_idx+1])=0    \n",
    "        for solo_instr in solo:\n",
    "            ((listens_dct[instr][solo_instr]).loc[start_idx:stop_idx+1])=0 \n",
    "        for rest_instr in resting:\n",
    "            ((listens_dct[instr][rest_instr]).loc[start_idx:stop_idx+1])=0 \n",
    "            \n",
    "    #deal with weight\n",
    "    \n",
    "    for instr in solo:\n",
    "        ((self_weight[instr]).loc[start_idx:stop_idx+1])=solo_weight\n",
    "    for instr in acc:\n",
    "        ((self_weight[instr]).loc[start_idx:stop_idx+1])=acc_weight\n",
    "    for instr in resting:\n",
    "        ((self_weight[instr]).loc[start_idx:stop_idx+1])=rest_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-supervision",
   "metadata": {},
   "source": [
    "# define listens dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "listens_dct = {}\n",
    "for instr in instrument_lst:\n",
    "    listens_dct[instr]= filled_comb_df.copy()\n",
    "    listens_dct[instr][instrument_lst]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Measures 1-5--> idx 0->34\n",
    "\n",
    "'clarinet_1' solo -> listens to acc + engine\n",
    "['horn_in_e_1', 'horn_in_e_2',\n",
    "                'bassoon_1','bassoon_2', ] acc-> listen  to clarinet 2 and eachother\n",
    "['clarinet_2']-> only listens to themselves\n",
    "\n",
    "['oboe_1', 'oboe_2']-> resting, listens only to cl2\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "solo = ['clarinet_1']\n",
    "acc = ['horn_in_e_1', 'horn_in_e_2',\n",
    "                'bassoon_1','bassoon_2', ]\n",
    "resting = ['oboe_1', 'oboe_2']\n",
    "\n",
    "start_idx = 0\n",
    "stop_idx = 34\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "'''\n",
    "Measures 5-8--> idx 25:62\n",
    "\n",
    "'oboe_1' solo -> listens to acc + engine\n",
    "['horn_in_e_1', 'horn_in_e_2', 'bassoon_1','bassoon_2', 'clarinet_2'] acc-> listen  to clarinet 2 and eachother\n",
    "\n",
    "\n",
    "['clarinet_1', 'oboe_2']-> resting, listens only to acc\n",
    "\n",
    "\n",
    "'''\n",
    "solo = ['oboe_1']\n",
    "acc = ['horn_in_e_1', 'horn_in_e_2', 'bassoon_1','bassoon_2', 'clarinet_2']\n",
    "resting = ['clarinet_1', 'oboe_2']\n",
    "\n",
    "start_idx = 25\n",
    "stop_idx = 62\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "'''\n",
    "Measures 8-13--> idx 62:104\n",
    "\n",
    "'horn_in_e_1' solo -> listens to acc + engine\n",
    "\n",
    "['oboe_1', 'oboe_2',  'bassoon_1','bassoon_2', 'clarinet_2'] acc-> listen  to themselves\n",
    "\n",
    "['horn_in_e_2']-> resting, listens only to acc\n",
    "\n",
    "\n",
    "'''\n",
    "solo = ['horn_in_e_1']\n",
    "acc = ['oboe_1', 'oboe_2',  'bassoon_1','bassoon_2', 'clarinet_2']\n",
    "resting = ['horn_in_e_2']\n",
    "\n",
    "start_idx = 62\n",
    "stop_idx = 104\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "'''\n",
    "Measures 13-14.5--> idx 104:116\n",
    "\n",
    "'bassoon_1' solo -> listens to acc \n",
    "\n",
    "['clarinet_1', 'clarinet_2','bassoon_2', 'horn_in_e_1'] acc-> listen  to clarinet 2 and eachother\n",
    "\n",
    "'''\n",
    "solo = ['bassoon_1']\n",
    "acc = ['clarinet_1', 'clarinet_2','bassoon_2', 'horn_in_e_1']\n",
    "resting = ['oboe_1', 'oboe_2','horn_in_e_2']\n",
    "\n",
    "start_idx = 104\n",
    "stop_idx = 116\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "'''\n",
    "Measures 14.5-16--> idx 116:128\n",
    "\n",
    "'horn_in_e_1' solo -> listens to acc \n",
    "\n",
    "['clarinet_1', 'clarinet_2','bassoon_2', 'bassoon_1'] acc-> \n",
    "\n",
    "'''\n",
    "solo = ['horn_in_e_1']\n",
    "acc = ['clarinet_1', 'clarinet_2','bassoon_2', 'bassoon_1']\n",
    "resting = ['oboe_1', 'oboe_2','horn_in_e_2']\n",
    "\n",
    "start_idx = 116\n",
    "stop_idx = 128\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "'''\n",
    "Measures 16-20.5--> idx 128:182\n",
    "\n",
    "['oboe_1', 'oboe_2', 'clarinet_1', 'clarinet_2'] solo -> listens to acc \n",
    "\n",
    "['horn_in_e_1', 'horn_in_e_2','bassoon_2', 'bassoon_1'] acc-> \n",
    "\n",
    "'''\n",
    "solo = ['oboe_1', 'oboe_2', 'clarinet_1', 'clarinet_2']\n",
    "acc = ['horn_in_e_1', 'horn_in_e_2','bassoon_2', 'bassoon_1']\n",
    "resting = []\n",
    "\n",
    "start_idx = 128\n",
    "stop_idx = 182\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "'''\n",
    "Measures 20.5-23--> idx 182:212\n",
    "\n",
    "['bassoon_1','horn_in_e_1', 'oboe_1'] soli -> listens to acc and eachother\n",
    "\n",
    "['bassoon_2', 'horn_in_e_2'] acc-> \n",
    "\n",
    "'''\n",
    "solo = []\n",
    "acc = ['bassoon_1','horn_in_e_1', 'oboe_1','bassoon_2', 'horn_in_e_2']\n",
    "resting = ['oboe_2', 'clarinet_1', 'clarinet_2']\n",
    "\n",
    "start_idx = 182\n",
    "stop_idx = 212\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "'''\n",
    "Measures 23-26.5 ---> idx 212:244\n",
    "\n",
    "listen equally\n",
    "'''\n",
    "\n",
    "solo = []\n",
    "acc = ['oboe_1','oboe_2','clarinet_1', 'clarinet_2',]\n",
    "resting = ['bassoon_1', 'bassoon_2','horn_in_e_1', 'horn_in_e_2']\n",
    "\n",
    "start_idx = 212\n",
    "stop_idx = 244\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "'''\n",
    "Measures 26.5-30.5 ---> idx 244:274\n",
    "\n",
    "['clarinet_1', 'bassoon_2', 'bassoon_1'] --> acc type\n",
    "'''\n",
    "solo = ['clarinet_1','bassoon_2', ]\n",
    "acc = ['bassoon_1']\n",
    "resting = ['oboe_1','oboe_2', 'clarinet_2', 'horn_in_e_1', 'horn_in_e_2']\n",
    "\n",
    "start_idx = 244\n",
    "stop_idx = 274\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "'''\n",
    "Measures 30.5-34--> idx 274:301\n",
    "\n",
    "listen equally\n",
    "'''\n",
    "\n",
    "solo = ['oboe_2','clarinet_1', 'clarinet_2',]\n",
    "acc = ['oboe_1']\n",
    "resting = ['bassoon_1', 'bassoon_2','horn_in_e_1', 'horn_in_e_2']\n",
    "start_idx = 274\n",
    "stop_idx = 301\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "'''\n",
    "Measures 34-->38 idx 301:310\n",
    "\n",
    "listen equally\n",
    "'''\n",
    "\n",
    "solo = []\n",
    "acc = ['oboe_1','oboe_2','clarinet_1', 'clarinet_2','bassoon_1', 'bassoon_2',]\n",
    "resting = ['horn_in_e_1', 'horn_in_e_2']\n",
    "start_idx = 301\n",
    "stop_idx = 310\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "\n",
    "'''\n",
    "Measures 38-->39 idx 310:317\n",
    "\n",
    "listen equally\n",
    "'''\n",
    "\n",
    "solo = ['clarinet_1']\n",
    "acc = ['oboe_1','oboe_2','clarinet_2','bassoon_1', 'bassoon_2','horn_in_e_1', 'horn_in_e_2']\n",
    "resting = []\n",
    "start_idx = 310\n",
    "stop_idx = 317\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "'''\n",
    "Measures 39-->43 idx 317:367\n",
    "\n",
    "listen equally\n",
    "'''\n",
    "\n",
    "solo = ['oboe_1']\n",
    "acc = ['clarinet_1','clarinet_2','bassoon_1', 'bassoon_2','horn_in_e_1', 'horn_in_e_2']\n",
    "resting = ['oboe_2']\n",
    "start_idx = 317\n",
    "stop_idx = 367\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "'''\n",
    "Measures 43-->48, 367:396\n",
    "\n",
    "listen equally\n",
    "'''\n",
    "\n",
    "solo = ['oboe_1', 'clarinet_1']\n",
    "acc = ['clarinet_2','bassoon_1', 'bassoon_2','horn_in_e_1', 'horn_in_e_2']\n",
    "resting = ['oboe_2']\n",
    "start_idx = 367\n",
    "stop_idx = 396\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "'''\n",
    "Measures 48-55, 396:508\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "solo = ['clarinet_1' , 'oboe_2','horn_in_e_1',]\n",
    "acc = ['bassoon_2','horn_in_e_2', 'clarinet_2', 'bassoon_1']\n",
    "resting = ['oboe_1']\n",
    "start_idx = 396\n",
    "stop_idx = 508\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "'''\n",
    "Measures 55-58, 508:556\n",
    "\n",
    "'''\n",
    "solo = ['oboe_1']\n",
    "acc = ['bassoon_2','horn_in_e_1', 'oboe_2', 'clarinet_1',\n",
    "       'horn_in_e_2', 'clarinet_2', 'bassoon_1']\n",
    "resting = []\n",
    "start_idx = 508\n",
    "stop_idx = 556\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "\n",
    "'''\n",
    "Measures 58-60, 556-570\n",
    "\n",
    "'''\n",
    "solo = ['oboe_1', ]\n",
    "acc = ['horn_in_e_1',  'clarinet_1',\n",
    "        'clarinet_2', 'bassoon_1']\n",
    "resting = ['oboe_2','horn_in_e_2','bassoon_2',]\n",
    "start_idx = 556\n",
    "stop_idx = 570\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "'''\n",
    "Measures 50-64, 570-623\n",
    "\n",
    "'''\n",
    "solo = ['oboe_1', 'clarinet_1','oboe_2','clarinet_2', ]\n",
    "acc = ['horn_in_e_1',  'horn_in_e_2','bassoon_2',\n",
    "        'bassoon_1']\n",
    "resting = []\n",
    "start_idx = 570\n",
    "stop_idx = 623\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)\n",
    "\n",
    "'''\n",
    "Measures 50-64, 570-623\n",
    "\n",
    "'''\n",
    "solo = ['oboe_1', 'clarinet_1','oboe_2','clarinet_2', ]\n",
    "acc = ['horn_in_e_1',  'horn_in_e_2','bassoon_2',\n",
    "        'bassoon_1']\n",
    "resting = []\n",
    "start_idx = 570\n",
    "stop_idx = 623\n",
    "\n",
    "\n",
    "assign(listens_dct, solo, acc, resting, start_idx, stop_idx, \n",
    "       self_weight, solo_weight, acc_weight, rest_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_weight_og=self_weight.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "filled_comb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-television",
   "metadata": {},
   "source": [
    "# ********Experiment with per row specified changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_acc_df = filled_comb_df.copy()\n",
    "\n",
    "#solo_acc_df = solo_acc_df.loc[solo_acc_df['eval_measure']<17]\n",
    "\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_b=len(solo_acc_df)\n",
    "#self contribution\n",
    "#tempo contribution\n",
    "tempo_percent = .03\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "#self contribution\n",
    "#self_weight= filled_comb_df*0+.8\n",
    "self_weight =self_weight*(1-tempo_percent)\n",
    "#average contribution\n",
    "avg_weight = (1-tempo_percent)-self_weight\n",
    "tempo = 700 #keep tempo same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = simulate_performance_listens(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=True, tempo_correction=True,\n",
    "                             const=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = sim_df.diff()\n",
    "for instr in instrument_lst:\n",
    "    print(\"\\n\", instr)\n",
    "    print(diff.loc[diff[instr]<=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio2=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio2, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"whole_audio/mozart_simulation_custom_df.wav\", sr_ensemble, stretched_full_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-latin",
   "metadata": {},
   "source": [
    "# *****Variable leader Experiment (everyone listens to everyone, but preserves leader roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "listens_dct = {}\n",
    "for instr in instrument_lst:\n",
    "    listens_dct[instr]= filled_comb_df.copy()\n",
    "    listens_dct[instr][instrument_lst]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_acc_df = filled_comb_df.copy()\n",
    "\n",
    "#solo_acc_df = solo_acc_df.loc[solo_acc_df['eval_measure']<17]\n",
    "\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_b=len(solo_acc_df)\n",
    "#self contribution\n",
    "#tempo contribution\n",
    "tempo_percent = .01\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "#self contribution\n",
    "#self_weight= filled_comb_df*0+.8\n",
    "self_weight =self_weight_og*(1-tempo_percent)\n",
    "#average contribution\n",
    "avg_weight = (1-tempo_percent)-self_weight\n",
    "tempo = 700 #keep tempo same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = simulate_performance_listens(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=True, tempo_correction=True,\n",
    "                             const=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = sim_df.diff()\n",
    "for instr in instrument_lst:\n",
    "    print(\"\\n\", instr)\n",
    "    print(diff.loc[diff[instr]<=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-attention",
   "metadata": {},
   "source": [
    "# *** Oboe 1 leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "listens_dct = {}\n",
    "for instr in instrument_lst:\n",
    "    listens_dct[instr]= filled_comb_df.copy()\n",
    "    listens_dct[instr][instrument_lst]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_acc_df = filled_comb_df.copy()\n",
    "\n",
    "#solo_acc_df = solo_acc_df.loc[solo_acc_df['eval_measure']<17]\n",
    "\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_b=len(solo_acc_df)\n",
    "#self contribution\n",
    "#tempo contribution\n",
    "tempo_percent = .05\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "#self contribution\n",
    "self_weight= filled_comb_df*0+.1\n",
    "self_weight['oboe_1']=.9\n",
    "\n",
    "#average contribution\n",
    "avg_weight = (1-tempo_percent)-self_weight\n",
    "tempo = 700 #keep tempo same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df=simulate_performance_listens(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=False, tempo_correction=True,\n",
    "                             const=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-leeds",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff = sim_df.diff()\n",
    "for instr in instrument_lst:\n",
    "    print(\"\\n\", instr)\n",
    "    print(diff.loc[diff[instr]<=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"whole_audio/mozart_simulation_noTempo.wav\", sr_ensemble, stretched_full_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-courage",
   "metadata": {},
   "source": [
    "# ******Medium version: all at .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "listens_dct = {}\n",
    "for instr in instrument_lst:\n",
    "    listens_dct[instr]= filled_comb_df.copy()\n",
    "    listens_dct[instr][instrument_lst]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_acc_df = filled_comb_df.copy()\n",
    "\n",
    "#solo_acc_df = solo_acc_df.loc[solo_acc_df['eval_measure']<17]\n",
    "\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_b=len(solo_acc_df)\n",
    "#self contribution\n",
    "#tempo contribution\n",
    "tempo_percent = .1\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "#self contribution\n",
    "self_weight= filled_comb_df*0+.5\n",
    "\n",
    "#average contribution\n",
    "avg_weight = (1-tempo_percent)-self_weight\n",
    "tempo = 700 #keep tempo same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df=simulate_performance_listens(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=True, tempo_correction=True,\n",
    "                             const=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = gen_mix_parts(stretched_parts, nonvar_mix, \"./parts_audio/sim_.6/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-resolution",
   "metadata": {},
   "source": [
    "# .7 leading with corrections ******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "#26.5-34\n",
    "start_idx1=244\n",
    "end_idx1 = 301\n",
    "#77-84\n",
    "start_idx2 = 769\n",
    "end_idx2 =794\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "listens_dct = {}\n",
    "for instr in instrument_lst:\n",
    "    listens_dct[instr]= filled_comb_df.copy()\n",
    "    listens_dct[instr][instrument_lst]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_acc_df = filled_comb_df.copy()\n",
    "\n",
    "#solo_acc_df = solo_acc_df.loc[solo_acc_df['eval_measure']<17]\n",
    "\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_p=8\n",
    "n_b=len(solo_acc_df)\n",
    "#self contribution\n",
    "#tempo contribution\n",
    "tempo_percent = .1\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "#self contribution\n",
    "self_weight= filled_comb_df*0+.6\n",
    "self_weight.iloc[start_idx1:end_idx1]=.4 #correct unravelng parts\n",
    "self_weight.iloc[start_idx2:end_idx2]=.4 #correct unravelng parts\n",
    "self_weight.iloc[:-10]=.4\n",
    "#average contribution\n",
    "avg_weight = (1-tempo_percent)-self_weight\n",
    "tempo = 700 #keep tempo same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df=simulate_performance_listens(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=True, tempo_correction=True,\n",
    "                             const=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-gravity",
   "metadata": {},
   "source": [
    "# *** Incorporating hand parsed leader - listens all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_weights_leader_manual(hand_parsed_lst, filled_comb_df, instrument_lst, \n",
    "                             lead_val, non_lead_val):\n",
    "    prev_val=0\n",
    "    solo_weight_df = filled_comb_df.copy()*0+non_lead_val\n",
    "    \n",
    "    for i in range(len(hand_parsed_lst)):\n",
    "        #current block\n",
    "        leader = hand_parsed_lst[i]\n",
    "        instr=leader[0]\n",
    "        lims=leader[1]\n",
    "\n",
    "        #print('lims[0] is ', lims[0])\n",
    "\n",
    "        cond = ((filled_comb_df['eval_measure']<=lims[1])&\n",
    "                        (lims[0] <=filled_comb_df['eval_measure']) )\n",
    "\n",
    " \n",
    "        #print(cond)\n",
    "\n",
    "        solo_weight_df[instr].loc[cond]= lead_val\n",
    "\n",
    "\n",
    "    return solo_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_weights =gen_weights_leader_manual(hand_parsed_leader1, filled_comb_df, instrument_lst, \n",
    "                             .8, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "listens_dct = {}\n",
    "for instr in instrument_lst:\n",
    "    listens_dct[instr]= filled_comb_df.copy()\n",
    "    listens_dct[instr][instrument_lst]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_acc_df = filled_comb_df.copy()\n",
    "\n",
    "#solo_acc_df = solo_acc_df.loc[solo_acc_df['eval_measure']<17]\n",
    "\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_b=len(solo_acc_df)\n",
    "#self contribution\n",
    "#tempo contribution\n",
    "tempo_percent = .2\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "#self contribution\n",
    "self_weight= solo_weights\n",
    "\n",
    "#average contribution\n",
    "avg_weight = (1-tempo_percent)-self_weight\n",
    "tempo = 700 #keep tempo same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df=simulate_performance_listens(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, listens_dct,\n",
    "                         tempo,catch_reverse=False, tempo_correction=True,\n",
    "                             const=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = sim_df.diff()\n",
    "for instr in instrument_lst:\n",
    "    print(\"\\n\", instr)\n",
    "    print(diff.loc[diff[instr]<=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-gossip",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-taiwan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-simon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "absolute-possibility",
   "metadata": {},
   "source": [
    "### Experiment 2: Incorporation of target tempo loss\n",
    "\n",
    "- each instrument listens to all other instruments\n",
    "- does not slow down because target tempo is incorporated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 seconds per measure \n",
    "\n",
    "n_b=len(filled_comb_df)\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_p = len(instrument_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-corporation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "other_instrument_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo=seconds_to_stft_frames(3.7)\n",
    "\n",
    "#tempo contribution\n",
    "tempo_percent = .15\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "#self contribution\n",
    "self_weight= filled_comb_df*0+.9\n",
    "self_weight *=(1-tempo_percent)\n",
    "#average contribution\n",
    "avg_weight = (1-tempo_percent)-self_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = simulate_performance_flex(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, \n",
    "                         instrument_lst, other_instrument_dct,\n",
    "                         tempo,catch_reverse=False, tempo_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = sim_df.diff()\n",
    "for instr in instrument_lst:\n",
    "    print(\"\\n\", instr)\n",
    "    print(diff.loc[diff[instr]<=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"whole_audio/mozart_simulationTempo.wav\", sr_ensemble, stretched_full_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-timber",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "\n",
    "- An instrument's 'freedom' can vary over time, where freedom is the importance placed on following their original part vs. following the group\n",
    "\n",
    "- Posit: When an instrument is resting, it has no freedom. When it is not resting, it has a lot of freedom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-theater",
   "metadata": {},
   "source": [
    "### This function \"listens\" only to notes that are currently playing\n",
    "\n",
    "- Note: for rests, everyone needs equal wieghtt (can't be row of zeros)\n",
    "\n",
    "Possibilties\n",
    "\n",
    "|                             | You are currently playing                 |You are currently resting |\n",
    "|-----------------------------|-------------------------------------------|----------------------------|\n",
    "| You were previously playing | s_w x self_trajectory + a_w x avg playing trajectory  |  0 x self_trajectory + 1 x avg playing trajectory |\n",
    "| You were previously resting | s_w x self_trajectory + a_w x avg playing trajectory|  0 x self_trajectory + 1 x avg playing trajectory |\n",
    "\n",
    "\n",
    "\n",
    "where avg playing trajectory is who was previously playing and where they would be now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_performance_curplay(input_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, tempo_weight,\n",
    "                         instrument_lst, tempo, catch_reverse=True):\n",
    "\n",
    "\n",
    "    #Note: check self_weight, there cannot be a row of zeros?\n",
    "    df = input_df.copy()\n",
    "    '''\n",
    "    Initialize simuation parameters \n",
    "    '''\n",
    "    m0 = df.loc[0]\n",
    "    m1 = df.loc[1]\n",
    "    diff0 = m1-m0\n",
    "    #switch with frames_per_measure later\n",
    "    first_beatlen = diff0['eval_measure']* tempo\n",
    "    #What multiple is needed to normalize tempo for all parts\n",
    "    tempo_multiple = diff0/first_beatlen\n",
    "    #normalize tempo by matching length of first note\n",
    "    df[instrument_lst]=(df / tempo_multiple)[instrument_lst]\n",
    "    \n",
    "    #calculate differences between relative note beats\n",
    "    #access i-2 th element for \n",
    "    df_diff = df.diff().dropna().reset_index(drop=True)\n",
    "\n",
    "    x1 = df_diff.loc[1:n_b-2].reset_index(drop=True)\n",
    "\n",
    "    x2 = df_diff.loc[0:n_b-3]      \n",
    "    #ratio between length of adjacent notes \n",
    "    ratios = x1.divide(x2)  \n",
    "\n",
    "\n",
    "    #Loop to update\n",
    "    i = 2\n",
    "\n",
    "    while i < n_b:\n",
    "        print(\"\\n***ON NOTE: \", i)\n",
    "\n",
    "        #prev values are all updated\n",
    "        prev_del = df.loc[i-1] - df.loc[i-2]\n",
    "        prev_beatlen = prev_del['eval_measure']\n",
    "        prev_diffs = prev_del[instrument_lst]\n",
    "        \n",
    "        #df.loc[i] is not yet updated\n",
    "        cur_del = df.loc[i] - df.loc[i-1]\n",
    "        cur_beatlen = cur_del['eval_measure']\n",
    "\n",
    "        \n",
    "\n",
    "        '''\n",
    "        Average predicted location based on other parts\n",
    "        Figure out which parts were previously playing\n",
    "        - 0 indicates playing\n",
    "        '''\n",
    "        \n",
    "                \n",
    "        \n",
    "        prev_rates = prev_diffs/prev_beatlen\n",
    "\n",
    "\n",
    "        #print(\"weights of previous note\\n\", self_weight.iloc[i-1])\n",
    "        prev_weights = self_weight.iloc[i-1]\n",
    "        \n",
    "        #pick out nonzero elements \n",
    "        prev_weights = prev_weights.loc[prev_weights !=0]\n",
    "        #print(\"prev_weights\", prev_weights)\n",
    "        \n",
    "        #extract which intruments were previously playing\n",
    "        prev_playing_instrs = list(prev_weights.keys())\n",
    "        #print('instruments previously playing', prev_playing_instrs)\n",
    "        \n",
    "        #calculate trajectory\n",
    "        pred_trajectory_loc = (prev_rates[prev_playing_instrs]*cur_beatlen\n",
    "                             ) + df[prev_playing_instrs].loc[i-1]\n",
    "        print(\"current trajectory for all instruments\\n\", pred_trajectory_loc)\n",
    "\n",
    "\n",
    "        avg_trajectory_loc = sum( pred_trajectory_loc)/len(prev_playing_instrs)            \n",
    "\n",
    "        '''\n",
    "       \n",
    "        \n",
    "        #make this a weighted sum: i.e. parts that listen less should contribute less\n",
    "        prev_instr_avg_weight = avg_weight[ prev_playing_instrs ].loc[i-2]\n",
    "        prev_instr_avg_weight=prev_instr_avg_weight/sum(prev_instr_avg_weight)\n",
    "        print('previous instrument weight contribution to average trajectory:\\n',\n",
    "              prev_instr_avg_weight)\n",
    "        avg_trajectory_loc =sum(prev_instr_avg_weight\n",
    "                                *pred_trajectory_loc)\n",
    "        '''       \n",
    "        print(\"average trajectory loc is \\n\", avg_trajectory_loc)\n",
    "\n",
    "        '''\n",
    "        Ascertain Each intrument's own part-based trajecotry\n",
    "        '''\n",
    "        #location of next note based on original part's ratio\n",
    "        #look at ratios indexing \n",
    "        self_trajectory_loc = df[instrument_lst].loc[i-1]+ prev_diff*ratios.loc[i-2]\n",
    "        \n",
    "        print(\"self_trajectory_loc\", self_trajectory_loc)\n",
    "\n",
    "        '''\n",
    "        Ascertain Tempo-based trajectory\n",
    "        '''\n",
    "        \n",
    "        tempo_trajectory_loc = df[instrument_lst].loc[i-1] + tempo * cur_beatlen\n",
    "\n",
    "        print('tempo_trajectory_loc', tempo_trajectory_loc)\n",
    "        \n",
    "        '''\n",
    "        Put it together\n",
    "        '''\n",
    "\n",
    "        #update\n",
    "        df.loc[i][instrument_lst] = (self_weight.loc[i] * self_trajectory_loc \n",
    "                                     + avg_weight.loc[i] * avg_trajectory_loc\n",
    "                                     +tempo_weight[i]* tempo_trajectory_loc) \n",
    "\n",
    "        #print(df)\n",
    "        \n",
    "        '''\n",
    "        Ensure all change is positive\n",
    "        '''\n",
    "        negatives = df.loc[i]<df.loc[i-1]\n",
    "        print(\"negatives?\", sum(negatives))\n",
    "        if catch_reverse:\n",
    "\n",
    "            df.loc[i][negatives]= df.loc[i-1]+ 2#ensure no negatives \n",
    "            \n",
    "\n",
    "        i +=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-midnight",
   "metadata": {},
   "source": [
    "### Define play indicator\n",
    "\n",
    "Play indicator has 1 when beat is represented by note onset, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_indicator = comb_df.fillna(0)\n",
    "play_indicator[play_indicator>0]=1\n",
    "play_indicator['eval_measure']= comb_df['eval_measure']\n",
    "play_indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-immunology",
   "metadata": {},
   "source": [
    "## Example 1 \n",
    "- Everyone listens 50% and follows 50%\n",
    "- Everyone \"listens\" only parts that are currently playing\n",
    "- Target tempo is 3.7 seconds per measure, and that has a 10% contribution to descision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 seconds per measure \n",
    "\n",
    "n_b=len(filled_comb_df)\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_p = len(instrument_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo=seconds_to_stft_frames(3.7)\n",
    "\n",
    "#tempo contribution\n",
    "tempo_percent = 0\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "#self contribution\n",
    "self_weight = play_indicator[instrument_lst].copy()\n",
    "self_weight= self_weight*.4\n",
    "self_weight['oboe_1']= .8\n",
    "self_weight *=(1-tempo_percent)\n",
    "#average contribution\n",
    "avg_weight = (1-tempo_percent)-self_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = simulate_performance_curplay(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, tempo_weight,\n",
    "                         instrument_lst, tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write(\"50-50.wav\", sr_ensemble, stretched_full_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-registrar",
   "metadata": {},
   "source": [
    "## Graph spread of ensemble error compared to average of each time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time_arr = sim_df[instrument_lst].to_numpy()\n",
    "\n",
    "avg_times = np.array([np.sum(final_time_arr, axis=1)/num_voices]).T\n",
    "\n",
    "all_difs = final_time_arr - avg_times\n",
    "\n",
    "plt.title(\"Simulation: 50% listen and 50% lead, 20% tempo\")\n",
    "plt.hist(all_difs.flatten(), bins=100)\n",
    "plt.xlabel(\"Difference from mean times (in frames)\")\n",
    "plt.ylabel(\"Number of timepoints\")\n",
    "plt.show()\n",
    "print(\"Inter quartile range is\", iqr(all_difs.flatten()))\n",
    "print(\"Maximum deviation\", np.max(np.abs(all_difs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-custody",
   "metadata": {},
   "source": [
    "### Example 3 Hand-parsed ('best possible version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hand_parsed_weights_mult(comb_df, play_indicator, \n",
    "                             instrument_lst, hand_parsed_lst, \n",
    "                             lead_weight, non_lead_weight):\n",
    "\n",
    "    self_weights = play_indicator.copy()\n",
    "    #\n",
    "    self_weights[self_weights==0.01]=0\n",
    "    #self_weights  = self_weights * non_lead_weight\n",
    "    print(self_weights)\n",
    "    for el in hand_parsed_lst:\n",
    "        instr = el[0]\n",
    "        lims=el[1]\n",
    "        #print(instr)\n",
    "\n",
    "        #print(lims)\n",
    "        cond = ((lims[0] <= self_weights['eval_measure'] ) \n",
    "                & (self_weights['eval_measure']<lims[1]))\n",
    "        #print(cond)\n",
    "        self_weights[instr][cond]=self_weights[instr][cond]*1.5#lead_weight\n",
    "        #print(self_weights)\n",
    "    return self_weights  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hand_parsed_weights(comb_df, \n",
    "                             instrument_lst, hand_parsed_lst, \n",
    "                             lead_weight, non_lead_weight):\n",
    "\n",
    "    self_weights = comb_df.fillna(0)\n",
    "    self_weights[self_weights>0]=1\n",
    "    self_weights['eval_measure']= comb_df['eval_measure']\n",
    "\n",
    "    self_weights  = self_weights * non_lead_weight\n",
    "    print(self_weights)\n",
    "    for el in hand_parsed_lst:\n",
    "        instr = el[0]\n",
    "        lims=el[1]\n",
    "        #print(instr)\n",
    "\n",
    "        #print(lims)\n",
    "        cond = ((lims[0] <= self_weights['eval_measure'] ) \n",
    "                & (self_weights['eval_measure']<lims[1]))\n",
    "        #print(cond)\n",
    "        self_weights[instr][cond]=lead_weight\n",
    "        #print(self_weights)\n",
    "    return self_weights  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tend to follow more if more people playing. \n",
    "variable_weights = pd.DataFrame(make_weight_arr(comb_df,instrument_lst, 0.01 ), columns=instrument_lst)\n",
    "variable_weights[variable_weights<=0.01]=0\n",
    "variable_weights['eval_measure']= filled_comb_df['eval_measure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_hand_parsed_weights(comb_df, variable_weights, \n",
    "                             instrument_lst, hand_parsed_leader1, \n",
    "                             .8, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 seconds per measure \n",
    "\n",
    "n_b=len(filled_comb_df)\n",
    "instrument_lst = [\"oboe_1\", \n",
    "                  \"oboe_2\", \n",
    "                  \"clarinet_1\", \n",
    "                  \"clarinet_2\", \n",
    "                  \"bassoon_1\", \n",
    "                  \"bassoon_2\", \n",
    "                  \"horn_in_e_1\", \n",
    "                  \"horn_in_e_2\"]\n",
    "n_p = len(instrument_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-second",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempo=seconds_to_stft_frames(4)\n",
    "\n",
    "#tempo contribution\n",
    "tempo_percent = 0\n",
    "tempo_weight = np.ones(n_b)*tempo_percent\n",
    "\n",
    "self_weight = make_hand_parsed_weights(comb_df, \n",
    "                             instrument_lst, hand_parsed_leader1, \n",
    "                             .8, .2)[instrument_lst]\n",
    "\n",
    "\n",
    "self_weight *=(1-tempo_percent)\n",
    "\n",
    "avg_weight = (1-tempo_percent)-self_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = simulate_performance_curplay(filled_comb_df, n_b, n_p, \n",
    "                         self_weight, avg_weight, tempo_weight,\n",
    "                         instrument_lst, tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, sim_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-colors",
   "metadata": {},
   "source": [
    "# Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-british",
   "metadata": {},
   "source": [
    "1. set tolerance\n",
    "\n",
    "2. Loop:\n",
    "    - a. Start new section\n",
    "    - b. Increment section by 1 timepoint\n",
    "    - c. scale beginning and end to match\n",
    "    - d. check if tolerance exceeded\n",
    "    - e. If tolerance exceeded, rollback 1 timepoint and start new section (a)\n",
    "    - f. If tolerance not exceeded, continue incrementing (b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_check_error(partition_df_ref,\n",
    "                          indicator_df, start_idx, stop_idx, tol):\n",
    "    section = partition_df_ref.iloc[start_idx:stop_idx+1] #get new version memory hog\n",
    "\n",
    "    #number of measures the section covers \n",
    "    dist_elapsed = (section['eval_measure'].loc[stop_idx]-\n",
    "                section['eval_measure'].loc[start_idx])\n",
    "    #not used, should be this much time elapsed for section\n",
    "    time_elapsed = dist_elapsed * tempo\n",
    "    #scale the section - assume first value is equivalent for all\n",
    "    tempo_multiplier = dist_elapsed/(\n",
    "        section.loc[stop_idx]- section.loc[start_idx])   \n",
    "    \n",
    "\n",
    "    # assign in new dataframe (will change every iteration)\n",
    "    scaled_section = tempo*(section[instrument_lst]* (tempo_multiplier[instrument_lst]))\n",
    "    #rest start to 0\n",
    "    scaled_section[instrument_lst]-=scaled_section[instrument_lst].iloc[0]\n",
    "    #Check if error has exceeded \n",
    "    error_exceeded = False\n",
    "    print(\"***************************\")\n",
    "    for i in range(start_idx, stop_idx+1):\n",
    "        scaled_section_row = scaled_section.loc[i]\n",
    "        indicator_section_row= indicator_df.loc[i]\n",
    "        curplay_instrument_series = scaled_section_row.loc[indicator_section_row>0]\n",
    "        mean = np.mean(curplay_instrument_series)\n",
    "        square_error =(curplay_instrument_series-mean)**2\n",
    "        print(\"\\nsquare error\", square_error)\n",
    "        #One instrument is too far from mean location\n",
    "        if sum(square_error>tol)>0:\n",
    "            error_exceeded=True\n",
    "            break\n",
    "    print(\"**************************\")      \n",
    "    \n",
    "    return error_exceeded, scaled_section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-scratch",
   "metadata": {},
   "source": [
    "## Experiment 1: absolute toleralance of 25 frames\n",
    "- single tolerance applied for all notes\n",
    "- tolerance could change depending on application (e.g. array of tolerances depending details of score)\n",
    "- this is a bit too much error for my taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_frames_to_seconds(8) #slighly more than a 32nd note at quarter = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_to_stft_frames(.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "partition_df_ref = filled_comb_df.copy()\n",
    "tol_abs=15\n",
    "tempo=seconds_to_stft_frames(4.1)\n",
    "n_b = len(partition_df_ref )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: \n",
    "#filled comb df (with interpolation)\n",
    "#comb_df (with NaN values in rests)\n",
    "#tolerance: absolute number of frames a timepoint can differ from the mean of that beat\n",
    "def create_partition_df_pointwise(partition_df_ref, comb_df, tol_abs, n_b, tempo):\n",
    "    \n",
    "    tol=tol_abs**2\n",
    "    partition_df_new=filled_comb_df.copy()\n",
    "    indicator_df = comb_df.fillna(0)\n",
    "    \n",
    "    start_idx=0\n",
    "    section_borders_lst = []\n",
    "    while start_idx < n_b-1:\n",
    "        print('\\n********\\nnew section starting at',start_idx)\n",
    "        stop_idx = start_idx\n",
    "        section_borders_lst.append(partition_df_ref['eval_measure'].iloc[start_idx])\n",
    "        #stop_idx can theoretically increase until the end of the piece\n",
    "        while stop_idx < n_b-1:\n",
    "            #increment \n",
    "            stop_idx +=1\n",
    "            print('\\nsection stopping at', stop_idx)\n",
    "            #get scaled version\n",
    "            isExceeded, scaled_section = scale_and_check_error(partition_df_ref,\n",
    "                                                               indicator_df, \n",
    "                                                               start_idx, stop_idx, tol)\n",
    "\n",
    "            #a False isExceeded means we repeat the process\n",
    "            if isExceeded == True:\n",
    "                \n",
    "                print(\"!!! tolerance exceeded \")\n",
    "                #roll back\n",
    "                stop_idx -=1\n",
    "             #get scaled version\n",
    "                isExceeded, scaled_section = scale_and_check_error(\n",
    "                    partition_df_ref,indicator_df, start_idx, stop_idx, tol)\n",
    "\n",
    "                shifted_scaled_section = (scaled_section[instrument_lst]+ \n",
    "                    partition_df_new[instrument_lst].iloc[start_idx])\n",
    "                print(\"final scaled section is\\n\", shifted_scaled_section)\n",
    "                #assign \n",
    "                '''\n",
    "                print('putting in\\n', scaled_section[instrument_lst]+ \n",
    "                    partition_df_new[instrument_lst].iloc[start_idx])\n",
    "                print('assigning to\\n', partition_df_new[instrument_lst].iloc[start_idx:stop_idx+1])\n",
    "                '''\n",
    "                (partition_df_new.iloc[start_idx:stop_idx+1])[instrument_lst]= (\n",
    "                    scaled_section[instrument_lst]+ \n",
    "                    partition_df_new[instrument_lst].iloc[start_idx])\n",
    "\n",
    "                print('new times\\n',partition_df_new[instrument_lst].iloc[start_idx:stop_idx+1])\n",
    "\n",
    "                break\n",
    "            #Must also stop if we've reached the end of the piece\n",
    "            elif stop_idx == n_b-1:\n",
    "                print(\"Need to end, currently stop is\", n_b-1)\n",
    "                shifted_scaled_section = (scaled_section[instrument_lst]+ \n",
    "                    partition_df_new[instrument_lst].iloc[start_idx])\n",
    "                print(\"final scaled section is\\n\", shifted_scaled_section)\n",
    "                #assign \n",
    "                (partition_df_new.iloc[start_idx:stop_idx+1])[instrument_lst]= (\n",
    "                    scaled_section[instrument_lst]+ \n",
    "                    partition_df_new[instrument_lst].iloc[start_idx])\n",
    "\n",
    "            \n",
    "        start_idx = stop_idx\n",
    "        print(start_idx, stop_idx)\n",
    "    return partition_df_new, section_borders_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df, section_lst=create_partition_df_pointwise(filled_comb_df, comb_df, 9, n_b, tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-bundle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(section_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, partition_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"whole_audio/mozart_partition_tolerance_9.wav\", sr_ensemble, stretched_full_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-review",
   "metadata": {},
   "source": [
    "## Experiment 2: Ensure strong beat alignment\n",
    "1. set tolerance\n",
    "\n",
    "2. Loop:\n",
    "    - a. Start new section.\n",
    "        - a1. Availible increments depend on modulus of measure. e.g. 2.25 could increment by quarter, while 2.5 could increment by half note or quarter. Increment must be in set [.0625, .125, .25, .5, 1, 2, 4, 8]\n",
    "    - b. Increment section by 1 timepoint\n",
    "    - c. scale beginning and end to match\n",
    "    - d. check if tolerance exceeded\n",
    "    - e. If tolerance exceeded, rollback 1 timepoint and start new section (a)\n",
    "    - f. If tolerance not exceeded, continue incrementing (b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_comb_df.loc[filled_comb_df['eval_measure']==20.1].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "increment_vals = [.0625, .125, .25, .5, 1., 2., 4., 8., 16.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: \n",
    "#filled comb df (with interpolation)\n",
    "#comb_df (with NaN values in rests)\n",
    "#tolerance: absolute number of frames a timepoint can differ from the mean of that beat\n",
    "\n",
    "# while start < end: \n",
    "#start with default size of 2. \n",
    "#if error not exceeded, increment, which will break out of loop\n",
    "#else, divdie size by 2\n",
    "\n",
    "def create_partition_df_bounded(partition_df_ref, \n",
    "                                comb_df, tol_abs, n_b, \n",
    "                                tempo, default_measure=2):\n",
    "    \n",
    "    tol=tol_abs**2\n",
    "    partition_df_new=filled_comb_df.copy()\n",
    "    indicator_df = comb_df.fillna(0)\n",
    "    \n",
    "    start_idx=0\n",
    "    prev_idx = 0\n",
    "    section_borders_lst = []\n",
    "    while start_idx < n_b-1:\n",
    "\n",
    "        start_measure = partition_df_ref['eval_measure'].iloc[start_idx]        \n",
    "        section_stop_measure = start_measure+ default_measure #set max distance   \n",
    "        print(\"SECTION MUST STOP AT \", section_stop_measure)\n",
    "        test_length = default_measure\n",
    "        #termination test:\n",
    "        while start_measure < section_stop_measure:     \n",
    "      \n",
    "            try: \n",
    "\n",
    "                #this is stopping point, will throw index error if does not exist\n",
    "                stop_idx = partition_df_ref.loc[partition_df_ref['eval_measure']==start_measure+test_length].index[0]\n",
    "                print(\"------\")\n",
    "                print(\"starting at index\", start_idx,\"= measure\", start_measure)\n",
    "                stop_measure = partition_df_ref['eval_measure'].iloc[stop_idx]\n",
    "                print(\"trying a stopping index of \", stop_idx, '= measure', stop_measure)\n",
    "                #test error level\n",
    "                isExceeded, scaled_section = scale_and_check_error(\n",
    "                        partition_df_ref,indicator_df, start_idx, stop_idx, tol)\n",
    "\n",
    "                #scale section if error not exceeded\n",
    "                if isExceeded == False:\n",
    "                    shifted_scaled_section = (scaled_section[instrument_lst]+ \n",
    "                        partition_df_new[instrument_lst].iloc[start_idx])\n",
    "                    print(\"final scaled section is\\n\", shifted_scaled_section)\n",
    "                    #assign \n",
    "                    (partition_df_new.iloc[start_idx:stop_idx+1])[instrument_lst]= (\n",
    "                        scaled_section[instrument_lst]+ \n",
    "                        partition_df_new[instrument_lst].iloc[start_idx])\n",
    "                    #record old section beginning location\n",
    "                    section_borders_lst.append(start_measure)\n",
    "                    #increment\n",
    "                    start_idx = stop_idx\n",
    "                    start_measure = partition_df_ref['eval_measure'].iloc[start_idx]  \n",
    "                else:\n",
    "                    #deal with this in exception clause\n",
    "                    raise ValueError(\"error exceeded at length \"+str(test_length))\n",
    "\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                #ending clause\n",
    "                if start_idx ==n_b-1:\n",
    "                    break\n",
    "                \n",
    "                test_length /= 2\n",
    "                print(\"test length halved is \", test_length)\n",
    "                #check if this stop measure will work\n",
    "                min_ending_measure = partition_base_df['eval_measure'].iloc[start_idx+1]\n",
    "                min_length = min_ending_measure - start_measure\n",
    "                print(\"next stop point in length\", min_length)\n",
    "                if min_length > test_length:\n",
    "                    test_length = min_length\n",
    "        \n",
    "                print(\"final test length is \", test_length)\n",
    "    return partition_df_new, section_borders_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "16 % 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_base_df=filled_comb_df.copy()\n",
    "partition_base_df['eval_measure']= filled_comb_df['eval_measure']-1\n",
    "partition_base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df, section_lst=create_partition_df_bounded(partition_base_df, \n",
    "                                                      comb_df, 500, n_b, tempo, \n",
    "                                                      default_measure = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "partition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stretch = assign_new_stft(df_dct, partition_df, instrument_lst)\n",
    "stretched_parts = create_final_parts(ensemble_audio_lst,final_stretch,instrument_lst, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = gen_mix_parts(stretched_parts, nonvar_mix, \"./parts_audio/big_beat_1meas/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_full_audio=sum_parts(stretched_parts)\n",
    "ipd.Audio(stretched_full_audio, rate=sr_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-harbor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Octover 15 demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlsp-env",
   "language": "python",
   "name": "mlsp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
